{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with different neural network architectures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Michał Gromadzki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(1337)\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1      advice Talk to your neighbours family to excha...            Positive  \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3      My food stock is not the only one which is emp...            Positive  \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  Airline pilots offering to stock supermarket s...             Neutral  \n",
       "41153  Response to complaint not provided citing COVI...  Extremely Negative  \n",
       "41154  You know itÂs getting tough when @KameronWild...            Positive  \n",
       "41155  Is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41156  @TartiiCat Well new/used Rift S are going for ...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification\n",
    "data = pd.read_csv('data/Corona_NLP_train.csv', encoding='latin-1')\n",
    "data_test = pd.read_csv('data/Corona_NLP_test.csv', encoding='latin-1')\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41157"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = data[int(0.8*len(data)):]\n",
    "data_train = data[:int(0.8*len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32925, 6), (8232, 6), (3798, 6))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_val.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower() #converting input to lowercase\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text) #Removing punctuations and special characters.\n",
    "    text = re.sub('\"','', text) #Removing double quotes.\n",
    "    text = re.sub(r\"'s\\b\",\"\",text) #Eliminating apostrophe.\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \"\", text) #Removing twitter handles\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text) #Removing non-alphabetical characters\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords]) #Removing stopwords.\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_train = [preprocess(text) for text in data_train[\"OriginalTweet\"].values]\n",
    "clean_text_val = [preprocess(text) for text in data_val[\"OriginalTweet\"].values]\n",
    "clean_text_test = [preprocess(text) for text in data_test[\"OriginalTweet\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentiment = np.unique(data.Sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extremely Negative': 0,\n",
       " 'Extremely Positive': 1,\n",
       " 'Negative': 2,\n",
       " 'Neutral': 3,\n",
       " 'Positive': 4}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {i:s for s,i in enumerate(Sentiment)}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = { i:ch for i,ch in enumerate(Sentiment)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[i] for i in s]\n",
    "decode = lambda l: itos[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = encode(data_train.Sentiment.values)\n",
    "labels_val = encode(data_val.Sentiment.values)\n",
    "labels_test = encode(data_test.Sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 2048\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(clean_text_train)\n",
    "x_train_seq = tokenizer.texts_to_sequences(clean_text_train)\n",
    "x_val_seq = tokenizer.texts_to_sequences(clean_text_val)\n",
    "x_test_seq = tokenizer.texts_to_sequences(clean_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(seq) for seq in x_train_seq])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile([len(seq) for seq in x_train_seq],0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(seq) for seq in x_train_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_len, padding='post')\n",
    "x_val_pad = pad_sequences(x_val_seq, maxlen=max_len, padding='post')\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.array(labels_train)\n",
    "labels_val = np.array(labels_val)\n",
    "labels_test = np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.reshape(labels_train, (len(labels_train),1))\n",
    "labels_val = np.reshape(labels_val, (len(labels_val),1))\n",
    "labels_test = np.reshape(labels_test, (len(labels_test),1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No embedding\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(max_len, activation='relu'),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 5s 4ms/step - loss: 31.9243 - accuracy: 0.2218 - val_loss: 7.4622 - val_accuracy: 0.2212\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 3.8931 - accuracy: 0.2350 - val_loss: 2.2629 - val_accuracy: 0.2451\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 2.2623 - accuracy: 0.2475 - val_loss: 1.9824 - val_accuracy: 0.2799\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 2.0941 - accuracy: 0.2482 - val_loss: 1.9942 - val_accuracy: 0.2004\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 1.9951 - accuracy: 0.2549 - val_loss: 1.8309 - val_accuracy: 0.2802\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 1.9856 - accuracy: 0.2536 - val_loss: 1.7384 - val_accuracy: 0.2496\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 1.9711 - accuracy: 0.2558 - val_loss: 2.2864 - val_accuracy: 0.2502\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 1.9236 - accuracy: 0.2555 - val_loss: 1.7851 - val_accuracy: 0.2761\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 1.9297 - accuracy: 0.2588 - val_loss: 2.1418 - val_accuracy: 0.2289\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 7s 7ms/step - loss: 1.9018 - accuracy: 0.2559 - val_loss: 1.9696 - val_accuracy: 0.2908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226da38fb50>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labels_train, epochs=10, batch_size=32, validation_data=(x_val_pad, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 6ms/step - loss: 2.0360 - accuracy: 0.2578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2577672600746155"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_pad, labels_test)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense - small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, n_embed,input_length=max_len),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(max_len * n_embed, activation='relu'),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 32, 4)             236612    \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      " softmax_16 (Softmax)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 253,769\n",
      "Trainable params: 253,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 11s 10ms/step - loss: 1.3203 - accuracy: 0.4311 - val_loss: 1.1122 - val_accuracy: 0.5647\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 8s 7ms/step - loss: 1.0827 - accuracy: 0.5770 - val_loss: 1.0590 - val_accuracy: 0.5943\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 5s 5ms/step - loss: 1.0442 - accuracy: 0.5969 - val_loss: 1.0463 - val_accuracy: 0.5975\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 6s 6ms/step - loss: 1.0213 - accuracy: 0.6046 - val_loss: 1.0547 - val_accuracy: 0.5911\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 6s 6ms/step - loss: 1.0050 - accuracy: 0.6125 - val_loss: 1.0521 - val_accuracy: 0.5968\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 5s 5ms/step - loss: 0.9909 - accuracy: 0.6185 - val_loss: 1.0502 - val_accuracy: 0.5983\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 6s 6ms/step - loss: 0.9815 - accuracy: 0.6212 - val_loss: 1.0549 - val_accuracy: 0.5946\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 6s 6ms/step - loss: 0.9718 - accuracy: 0.6260 - val_loss: 1.0606 - val_accuracy: 0.5906\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 6s 6ms/step - loss: 0.9633 - accuracy: 0.6320 - val_loss: 1.0654 - val_accuracy: 0.5935\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 6s 6ms/step - loss: 0.9559 - accuracy: 0.6340 - val_loss: 1.0685 - val_accuracy: 0.5852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d939d510>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labels_train, epochs=10, batch_size=32, validation_data=(x_val_pad, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 1.1566 - accuracy: 0.5477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5476566553115845"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_pad, labels_test)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense - large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 16\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, n_embed,input_length=max_len),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(max_len * n_embed, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, 32, 16)            946448    \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      " softmax_17 (Softmax)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,242,261\n",
      "Trainable params: 1,242,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 10s 10ms/step - loss: 1.2312 - accuracy: 0.4834 - val_loss: 1.0658 - val_accuracy: 0.5914\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 20s 19ms/step - loss: 1.0321 - accuracy: 0.5979 - val_loss: 1.0562 - val_accuracy: 0.5831\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 18s 18ms/step - loss: 0.9551 - accuracy: 0.6320 - val_loss: 1.0866 - val_accuracy: 0.5735\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 17s 16ms/step - loss: 0.8678 - accuracy: 0.6730 - val_loss: 1.1483 - val_accuracy: 0.5613\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 9s 9ms/step - loss: 0.7670 - accuracy: 0.7184 - val_loss: 1.2340 - val_accuracy: 0.5590\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 10s 10ms/step - loss: 0.6517 - accuracy: 0.7646 - val_loss: 1.3718 - val_accuracy: 0.5483\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 24s 23ms/step - loss: 0.5297 - accuracy: 0.8117 - val_loss: 1.6249 - val_accuracy: 0.5353\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 16s 15ms/step - loss: 0.4084 - accuracy: 0.8610 - val_loss: 1.8778 - val_accuracy: 0.5197\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 22s 21ms/step - loss: 0.3086 - accuracy: 0.8962 - val_loss: 2.2256 - val_accuracy: 0.5136\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 22s 21ms/step - loss: 0.2391 - accuracy: 0.9192 - val_loss: 2.4699 - val_accuracy: 0.5151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d9e22a10>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labels_train, epochs=10, batch_size=32, validation_data=(x_val_pad, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 7ms/step - loss: 2.7646 - accuracy: 0.4663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46629804372787476"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_pad, labels_test)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, n_embed,input_length=max_len),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(max_len * n_embed, return_sequences=True)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, 32, 4)             236612    \n",
      "                                                                 \n",
      " bidirectional_15 (Bidirecti  (None, 32, 256)          34048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 5)                 40965     \n",
      "                                                                 \n",
      " softmax_18 (Softmax)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 311,625\n",
      "Trainable params: 311,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 132s 126ms/step - loss: 1.2847 - accuracy: 0.4528 - val_loss: 1.1086 - val_accuracy: 0.5694\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 137s 133ms/step - loss: 1.1138 - accuracy: 0.5577 - val_loss: 1.0889 - val_accuracy: 0.5836\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 120s 117ms/step - loss: 1.0915 - accuracy: 0.5708 - val_loss: 1.0822 - val_accuracy: 0.5799\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 134s 131ms/step - loss: 1.0787 - accuracy: 0.5820 - val_loss: 1.0872 - val_accuracy: 0.5764\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 144s 140ms/step - loss: 1.0686 - accuracy: 0.5828 - val_loss: 1.0947 - val_accuracy: 0.5779\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 159s 155ms/step - loss: 1.0585 - accuracy: 0.5893 - val_loss: 1.0810 - val_accuracy: 0.5838\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 159s 154ms/step - loss: 1.0518 - accuracy: 0.5925 - val_loss: 1.1050 - val_accuracy: 0.5695\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 157s 152ms/step - loss: 1.0480 - accuracy: 0.5921 - val_loss: 1.0906 - val_accuracy: 0.5808\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 145s 141ms/step - loss: 1.0425 - accuracy: 0.5944 - val_loss: 1.0979 - val_accuracy: 0.5762\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 160s 156ms/step - loss: 1.0403 - accuracy: 0.5980 - val_loss: 1.0988 - val_accuracy: 0.5713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d945cb80>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labels_train, epochs=10, batch_size=32, validation_data=(x_val_pad, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 2s 16ms/step - loss: 1.1974 - accuracy: 0.5250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5250131487846375"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_pad, labels_test)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, n_embed,input_length=max_len),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(max_len * n_embed,return_sequences=True)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, 32, 4)             236612    \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, 32, 256)          102912    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 5)                 40965     \n",
      "                                                                 \n",
      " softmax_19 (Softmax)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 380,489\n",
      "Trainable params: 380,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 30s 25ms/step - loss: 1.2541 - accuracy: 0.4733 - val_loss: 1.0705 - val_accuracy: 0.5907\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 31s 30ms/step - loss: 1.0842 - accuracy: 0.5805 - val_loss: 1.0612 - val_accuracy: 0.5897\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 29s 28ms/step - loss: 1.0630 - accuracy: 0.5874 - val_loss: 1.0468 - val_accuracy: 0.5968\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 24s 24ms/step - loss: 1.0444 - accuracy: 0.5957 - val_loss: 1.0470 - val_accuracy: 0.5984\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 28s 27ms/step - loss: 1.0275 - accuracy: 0.5973 - val_loss: 1.0461 - val_accuracy: 0.6101\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 28s 28ms/step - loss: 1.0127 - accuracy: 0.6058 - val_loss: 1.0410 - val_accuracy: 0.6016\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 28s 27ms/step - loss: 1.0021 - accuracy: 0.6085 - val_loss: 1.0626 - val_accuracy: 0.5948\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 24s 23ms/step - loss: 0.9932 - accuracy: 0.6121 - val_loss: 1.0565 - val_accuracy: 0.5931\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 24s 23ms/step - loss: 0.9828 - accuracy: 0.6146 - val_loss: 1.0622 - val_accuracy: 0.6000\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 25s 24ms/step - loss: 0.9771 - accuracy: 0.6188 - val_loss: 1.0690 - val_accuracy: 0.5924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d9bf7eb0>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labels_train, epochs=10, batch_size=32, validation_data=(x_val_pad, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 8ms/step - loss: 1.1707 - accuracy: 0.5411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.541074275970459"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_pad, labels_test)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, n_embed,input_length=max_len),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(max_len * n_embed,return_sequences=True)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_19 (Embedding)    (None, 32, 4)             236612    \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirecti  (None, 32, 256)          136192    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 5)                 40965     \n",
      "                                                                 \n",
      " softmax_20 (Softmax)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 413,769\n",
      "Trainable params: 413,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 28s 24ms/step - loss: 1.3009 - accuracy: 0.4494 - val_loss: 1.0905 - val_accuracy: 0.5788\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 23s 22ms/step - loss: 1.0918 - accuracy: 0.5726 - val_loss: 1.0613 - val_accuracy: 0.5914\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 22s 22ms/step - loss: 1.0638 - accuracy: 0.5862 - val_loss: 1.0384 - val_accuracy: 0.6018\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 22s 22ms/step - loss: 1.0488 - accuracy: 0.5963 - val_loss: 1.0418 - val_accuracy: 0.5978\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 24s 23ms/step - loss: 1.0367 - accuracy: 0.5994 - val_loss: 1.0392 - val_accuracy: 0.6080\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 30s 30ms/step - loss: 1.0244 - accuracy: 0.6056 - val_loss: 1.0267 - val_accuracy: 0.6080\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 31s 30ms/step - loss: 1.0144 - accuracy: 0.6068 - val_loss: 1.0441 - val_accuracy: 0.6001\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 26s 25ms/step - loss: 1.0053 - accuracy: 0.6118 - val_loss: 1.0319 - val_accuracy: 0.6078\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 23s 23ms/step - loss: 0.9943 - accuracy: 0.6147 - val_loss: 1.0398 - val_accuracy: 0.6078\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 23s 22ms/step - loss: 0.9885 - accuracy: 0.6174 - val_loss: 1.0519 - val_accuracy: 0.6043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22831167f40>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labels_train, epochs=10, batch_size=32, validation_data=(x_val_pad, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 9ms/step - loss: 1.1566 - accuracy: 0.5513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.551342785358429"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_pad, labels_test)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv - small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, n_embed,input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(max_len * n_embed,n_embed * 4,padding=\"same\"),  \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, 32, 4)             236612    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 128)           8320      \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 5)                 20485     \n",
      "                                                                 \n",
      " softmax_21 (Softmax)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,417\n",
      "Trainable params: 265,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 17s 11ms/step - loss: 1.2459 - accuracy: 0.4795 - val_loss: 1.0924 - val_accuracy: 0.5810\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 1.0968 - accuracy: 0.5726 - val_loss: 1.0769 - val_accuracy: 0.5909\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 10s 10ms/step - loss: 1.0798 - accuracy: 0.5828 - val_loss: 1.0773 - val_accuracy: 0.5844\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 10s 10ms/step - loss: 1.0661 - accuracy: 0.5896 - val_loss: 1.0925 - val_accuracy: 0.5753\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 10s 10ms/step - loss: 1.0551 - accuracy: 0.5925 - val_loss: 1.0995 - val_accuracy: 0.5788\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 1.0469 - accuracy: 0.5954 - val_loss: 1.0894 - val_accuracy: 0.5831\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 12s 12ms/step - loss: 1.0432 - accuracy: 0.5996 - val_loss: 1.0936 - val_accuracy: 0.5735\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 13s 12ms/step - loss: 1.0391 - accuracy: 0.5988 - val_loss: 1.0936 - val_accuracy: 0.5756\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 9s 9ms/step - loss: 1.0353 - accuracy: 0.6029 - val_loss: 1.1020 - val_accuracy: 0.5754\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 9s 9ms/step - loss: 1.0338 - accuracy: 0.6057 - val_loss: 1.0982 - val_accuracy: 0.5718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2284e37d150>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labels_train, epochs=10, batch_size=32, validation_data=(x_val_pad, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 6ms/step - loss: 1.1924 - accuracy: 0.5258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5258030295372009"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_pad, labels_test)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv - large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 16\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, n_embed,input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(max_len * n_embed,n_embed*4,padding=\"same\"),  \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_21 (Embedding)    (None, 32, 16)            946448    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 32, 512)           524800    \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 5)                 81925     \n",
      "                                                                 \n",
      " softmax_22 (Softmax)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,553,173\n",
      "Trainable params: 1,553,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 43s 38ms/step - loss: 1.2355 - accuracy: 0.4839 - val_loss: 1.1101 - val_accuracy: 0.5610\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 31s 30ms/step - loss: 1.1081 - accuracy: 0.5597 - val_loss: 1.1027 - val_accuracy: 0.5711\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 35s 34ms/step - loss: 1.0687 - accuracy: 0.5764 - val_loss: 1.1257 - val_accuracy: 0.5452\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 30s 29ms/step - loss: 1.0320 - accuracy: 0.5963 - val_loss: 1.1523 - val_accuracy: 0.5390\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 20s 20ms/step - loss: 0.9964 - accuracy: 0.6121 - val_loss: 1.2047 - val_accuracy: 0.5369\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 26s 25ms/step - loss: 0.9654 - accuracy: 0.6250 - val_loss: 1.1942 - val_accuracy: 0.5425\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 28s 27ms/step - loss: 0.9404 - accuracy: 0.6354 - val_loss: 1.2350 - val_accuracy: 0.5222\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 24s 23ms/step - loss: 0.9238 - accuracy: 0.6416 - val_loss: 1.2598 - val_accuracy: 0.5227\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 16s 15ms/step - loss: 0.9046 - accuracy: 0.6498 - val_loss: 1.3009 - val_accuracy: 0.5151\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 23s 23ms/step - loss: 0.8941 - accuracy: 0.6544 - val_loss: 1.2918 - val_accuracy: 0.5152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2287a240220>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labels_train, epochs=10, batch_size=32, validation_data=(x_val_pad, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 3s 26ms/step - loss: 1.4447 - accuracy: 0.4679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4678778350353241"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_pad, labels_test)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 32\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, n_embed,input_length=max_len),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 32)            1892896   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 32, 256)          164864    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               73984     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,136,229\n",
      "Trainable params: 2,136,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "129/129 [==============================] - 16s 47ms/step - loss: 1.3965 - accuracy: 0.3835 - val_loss: 1.1458 - val_accuracy: 0.5307\n",
      "Epoch 2/7\n",
      "129/129 [==============================] - 4s 35ms/step - loss: 1.0030 - accuracy: 0.6119 - val_loss: 0.9318 - val_accuracy: 0.6545\n",
      "Epoch 3/7\n",
      "129/129 [==============================] - 5s 35ms/step - loss: 0.9082 - accuracy: 0.6651 - val_loss: 0.9160 - val_accuracy: 0.6725\n",
      "Epoch 4/7\n",
      "129/129 [==============================] - 5s 38ms/step - loss: 0.8790 - accuracy: 0.6832 - val_loss: 0.9192 - val_accuracy: 0.6656\n",
      "Epoch 5/7\n",
      "129/129 [==============================] - 5s 36ms/step - loss: 0.8607 - accuracy: 0.6939 - val_loss: 0.9247 - val_accuracy: 0.6652\n",
      "Epoch 6/7\n",
      "129/129 [==============================] - 4s 34ms/step - loss: 0.8433 - accuracy: 0.6998 - val_loss: 0.9216 - val_accuracy: 0.6655\n",
      "Epoch 7/7\n",
      "129/129 [==============================] - 4s 34ms/step - loss: 0.8308 - accuracy: 0.7062 - val_loss: 0.9284 - val_accuracy: 0.6673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b7440f850>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labels_train, epochs=7, batch_size=256, validation_data=(x_val_pad, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 2s 13ms/step - loss: 1.0143 - accuracy: 0.6195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6195365786552429"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_pad, labels_test)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just got back from the grocery store. Still no hand sanitizer or hand soap, limited TP. But bottled water and bread were full. Vibe was like any other Sunday. #coronavirus #panicshopping #StayCalm\n",
      "Sentiment: Extremely Positive\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "People. If you are coughing or feeling sick stay at home. Do not go to the grocery store. Do not go to work. Please. This would be over if you just did that. #COVID19 #coronavirus #Pandumbic\n",
      "Sentiment: Negative\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "More than 4.4 million Canadians say they feel food insecure due to financial constraints: report https://t.co/3GPXCThrNM https://t.co/t507X4oG9k\n",
      "Sentiment: Neutral\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "IÂm at the grocery store just trying to buy some regular stuff (veggies, beans, eggs...) and itÂs way overcrowded with preppers loading up on soda, cereal, chips. When they survive the #Covid_19 scare theyÂll be sick with type 2 diabetes.\n",
      "Sentiment: Extremely Negative\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "I've had asthma for decades, almost died from pneumonia a few years ago and I'm close to 60 but I'll still be going to work tomorrow cuz I work in a retail store and we need to fill all the shelves the stupid hoarders empty every day since last week !\n",
      "#coronavirus\n",
      "Sentiment: Extremely Negative\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "How many Retail store CEOs can I get to compliment me? \n",
      "\n",
      "that seems to be this goal of this #TrumpPressConference \n",
      "\n",
      "I bet these stores would love a payroll tax cut, they'd save a ton of money which would have gone into workers' social security fund. \n",
      "#coronavirus\n",
      "Sentiment: Extremely Positive\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Reality check: COVID-19 has made customer service workers remarkably like first responders. Cashiers at supermarkets. Airline counter agents. Hotel and restaurant staff. Retail store employees. Bank clerks. The list goes on. 1/\n",
      "Sentiment: Positive\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Some helpful words as several school systems make the choice to close down schools to combat community transmission of the coronavirus.  #coronavirus  \n",
      "\n",
      "https://t.co/4H0HWQkmkP\n",
      "Sentiment: Positive\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Still love the humanity in times of crisis. Guy next to me in line at grocery store just shared a recipe #Covid_19 #PeoplePower\n",
      "Sentiment: Positive\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "No, witch hazel won't help protect you from #coronavirus ...even in a DIY hand sanitizer: https://t.co/DYyShJHRGm @AmeshAA\n",
      "Sentiment: Extremely Positive\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "choices = np.random.choice(data_test[\"OriginalTweet\"].values,10)\n",
    "choices_vec = tokenizer.texts_to_sequences(choices)\n",
    "choices_vec = pad_sequences(choices_vec, maxlen=max_len, padding='post')\n",
    "preds = model.predict(choices_vec, verbose=0)\n",
    "for choice,pred in zip(choices,preds):\n",
    "    print(choice)\n",
    "    print(f\"Sentiment: {decode(np.argmax(pred))}\")\n",
    "    print(\"-\" * 200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model in model.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
