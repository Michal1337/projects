{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation with cross-attention"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Michał Gromadzki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 01:34:16.974545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-17 01:34:17.909635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_text as tf_text\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "tf.random.set_seed(1337)\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = path_to_file.read_text(encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Go.', 'Ve.'],\n",
       " ['Go.', 'Vete.'],\n",
       " ['Go.', 'Vaya.'],\n",
       " ['Go.', 'Váyase.'],\n",
       " ['Hi.', 'Hola.'],\n",
       " ['Run!', '¡Corre!'],\n",
       " ['Run.', 'Corred.'],\n",
       " ['Who?', '¿Quién?'],\n",
       " ['Fire!', '¡Fuego!'],\n",
       " ['Fire!', '¡Incendio!']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = text.splitlines()\n",
    "pairs = [line.split('\\t') for line in lines]\n",
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118964, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs), len(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pairs[:,0]\n",
    "context = pairs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118964,), (118964,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape, context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('¿Dirías que es verdad?', \"Would you say that's true?\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_context = context[1337]\n",
    "example_target = target[1337]\n",
    "example_context, example_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 01:34:22.398635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 01:34:22.471414: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 01:34:22.471531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 01:34:22.476404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 01:34:22.476493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 01:34:22.476532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 01:34:23.480823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 01:34:23.481166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 01:34:23.481216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-17 01:34:23.481356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 01:34:23.481429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3877 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n = int(0.8*len(context))\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context[:n], target[:n]))\n",
    "    .shuffle(10000)\n",
    "    .batch(batch_size))\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context[n:], target[n:]))\n",
    "    .shuffle(10000)\n",
    "    .batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Split accented characters.\n",
    "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "    text = tf.strings.lower(text)\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'[START] \\xc2\\xbf dirias que es verdad ? [END]',\n",
       " b'[START] would you say thats true ? [END]')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_context = preprocess(example_context)\n",
    "example_target = preprocess(example_target)\n",
    "example_context.numpy(), example_target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 01:34:24.543289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [95171]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 8192\n",
    "processor_spa = tf.keras.layers.TextVectorization(\n",
    "    standardize=preprocess,\n",
    "    max_tokens=vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "processor_spa.adapt(train_raw.map(lambda context, target: context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor_spa.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 01:34:30.099665: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [95171]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "processor_eng = tf.keras.layers.TextVectorization(\n",
    "    standardize=preprocess,\n",
    "    max_tokens=vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "processor_eng.adapt(train_raw.map(lambda context, target: target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor_eng.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2,    1,   13, 5577,    5,   15,  109,   12,    1,    3]),\n",
       " array([  2, 397,  78,   8, 135, 146, 289,  11, 535,   3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_context = processor_spa(example_context)\n",
    "example_target = processor_eng(example_target)\n",
    "example_context.numpy(), example_target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(context, target):\n",
    "    context = processor_spa(context).to_tensor()\n",
    "    target = processor_eng(target)\n",
    "    targ_in = target[:,:-1].to_tensor()\n",
    "    targ_out = target[:,1:].to_tensor()\n",
    "    return (context, targ_in), targ_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_raw.map(prepare_text)\n",
    "val_ds = val_raw.map(prepare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   86    5   15   42  106 1243    5   10  500]\n",
      "\n",
      "[   2    6   65   51 1673 1427   16    9   49  406]\n",
      "[   6   65   51 1673 1427   16    9   49  406    4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 01:34:34.965510: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_18' with dtype int64\n",
      "\t [[{{node Placeholder/_18}}]]\n"
     ]
    }
   ],
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "    print(ex_context_tok[0, :10].numpy()) \n",
    "    print()\n",
    "    print(ex_tar_in[0, :10].numpy()) \n",
    "    print(ex_tar_out[0, :10].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id_eng = tf.keras.layers.StringLookup(\n",
    "        vocabulary=processor_eng.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id_spa = tf.keras.layers.StringLookup(\n",
    "        vocabulary=processor_spa.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word_eng = tf.keras.layers.StringLookup(\n",
    "        vocabulary=processor_eng.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]',\n",
    "        invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word_spa = tf.keras.layers.StringLookup(\n",
    "        vocabulary=processor_spa.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]',\n",
    "        invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'[START]' b'este' b'es' b'el' b'museo' b'mas' b'grande' b'de' b'la'\n",
      " b'ciudad']\n",
      "\n",
      "[b'[START]' b'this' b'is' b'the' b'largest' b'museum' b'in' b'the' b'city'\n",
      " b'.']\n",
      "[b'this' b'is' b'the' b'largest' b'museum' b'in' b'the' b'city' b'.'\n",
      " b'[END]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 01:34:35.516698: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype string\n",
      "\t [[{{node Placeholder/_13}}]]\n"
     ]
    }
   ],
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "    print(id_to_word_spa(ex_context_tok[0, :10]).numpy()) \n",
    "    print()\n",
    "    print(id_to_word_eng(ex_tar_in[0, :10]).numpy()) \n",
    "    print(id_to_word_eng(ex_tar_out[0, :10]).numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 256\n",
    "n_embed = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, n_embed):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, n_embed, mask_zero=True)\n",
    "        self.rnn = tf.keras.layers.Bidirectional(merge_mode='sum',\n",
    "            layer=tf.keras.layers.GRU(units, return_sequences=True))      \n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.rnn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 01:34:36.960581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 18]), TensorShape([64, 18, 256]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(n_units, n_embed)\n",
    "ex_context = encoder(ex_context_tok)\n",
    "\n",
    "ex_context_tok.shape, ex_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=n_heads, **kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, x, context):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=context,\n",
    "            return_attention_scores=False)\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, n_embed):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, n_embed, mask_zero=True)\n",
    "        self.rnn = tf.keras.layers.GRU(units, return_sequences=True, return_state=True)\n",
    "        self.attention = CrossAttention(units)\n",
    "        self.output_layer = tf.keras.layers.Dense(self.vocab_size)\n",
    "\n",
    "    def get_initial_state(self, context):\n",
    "        batch_size = tf.shape(context)[0]\n",
    "        start_tokens = tf.fill([batch_size, 1], word_to_id_spa('[START]'))\n",
    "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "        embed = self.embedding(start_tokens)\n",
    "        return start_tokens, done, self.rnn.get_initial_state(embed)[0]\n",
    "    \n",
    "    def get_next_token(self, context, next_token, done, state):\n",
    "        logits, state = self(context, next_token, state = state, return_state=True) \n",
    "        logits = logits[:, -1, :]\n",
    "        next_token = tf.random.categorical(logits, num_samples=1)\n",
    "        done = done | (next_token == word_to_id_eng('[END]'))\n",
    "        next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
    "        return next_token, done, state\n",
    "\n",
    "    def call(self, context, x, state=None, return_state=False):  \n",
    "        x = self.embedding(x)\n",
    "        x, state = self.rnn(x, initial_state=state)\n",
    "        x = self.attention(x, context)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        if return_state:\n",
    "            return logits, state\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 17, 8192])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(n_units, n_embed)\n",
    "logits = decoder(ex_context, ex_tar_in)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, units, n_embed):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(units, n_embed)\n",
    "        self.decoder = Decoder(units, n_embed)\n",
    "\n",
    "    def get_initial_state(self, context):\n",
    "        return self.decoder.get_initial_state(context)\n",
    "    \n",
    "    def get_next_token(self, context, next_token, done, state):\n",
    "        return self.decoder.get_next_token(context, next_token, done, state)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        context, x = inputs\n",
    "        context = self.encoder(context)\n",
    "        logits = self.decoder(context, x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 17, 8192])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_units = 1024\n",
    "n_embed = 64\n",
    "model = Model(n_units, n_embed)\n",
    "logits = model((ex_context_tok, ex_tar_in))\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_1 (Encoder)         multiple                  7221248   \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  29062144  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,283,392\n",
      "Trainable params: 36,283,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "            metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 21:35:02.211257: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_16' with dtype int64\n",
      "\t [[{{node Placeholder/_16}}]]\n",
      "2023-05-16 21:35:09.069370: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-05-16 21:35:16.065551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 4.8673 - accuracy: 0.2935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 21:36:00.911481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype int64\n",
      "\t [[{{node Placeholder/_12}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 67s 456ms/step - loss: 4.8673 - accuracy: 0.2935 - val_loss: 3.9834 - val_accuracy: 0.3727\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 3.6889 - accuracy: 0.4039 - val_loss: 3.3703 - val_accuracy: 0.4407\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 3.1506 - accuracy: 0.4724 - val_loss: 2.9999 - val_accuracy: 0.4854\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 2.7397 - accuracy: 0.5310 - val_loss: 2.5541 - val_accuracy: 0.5558\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 2.4736 - accuracy: 0.5681 - val_loss: 2.2986 - val_accuracy: 0.5947\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 2.2912 - accuracy: 0.5969 - val_loss: 2.1868 - val_accuracy: 0.6095\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 34s 340ms/step - loss: 2.1069 - accuracy: 0.6208 - val_loss: 1.9734 - val_accuracy: 0.6393\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 2.0116 - accuracy: 0.6390 - val_loss: 1.8701 - val_accuracy: 0.6540\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 34s 337ms/step - loss: 1.8693 - accuracy: 0.6565 - val_loss: 1.8178 - val_accuracy: 0.6610\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 33s 329ms/step - loss: 1.8014 - accuracy: 0.6683 - val_loss: 1.7326 - val_accuracy: 0.6754\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.7277 - accuracy: 0.6775 - val_loss: 1.6421 - val_accuracy: 0.6853\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 41s 407ms/step - loss: 1.6442 - accuracy: 0.6902 - val_loss: 1.6236 - val_accuracy: 0.6883\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 1.5827 - accuracy: 0.6965 - val_loss: 1.6123 - val_accuracy: 0.6920\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.5496 - accuracy: 0.7007 - val_loss: 1.5043 - val_accuracy: 0.7100\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 40s 397ms/step - loss: 1.5170 - accuracy: 0.7080 - val_loss: 1.5233 - val_accuracy: 0.7020\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 39s 391ms/step - loss: 1.4180 - accuracy: 0.7180 - val_loss: 1.4387 - val_accuracy: 0.7161\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 40s 396ms/step - loss: 1.3604 - accuracy: 0.7242 - val_loss: 1.4363 - val_accuracy: 0.7234\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 34s 343ms/step - loss: 1.3068 - accuracy: 0.7350 - val_loss: 1.4317 - val_accuracy: 0.7193\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 36s 360ms/step - loss: 1.2711 - accuracy: 0.7376 - val_loss: 1.3713 - val_accuracy: 0.7310\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 1.2629 - accuracy: 0.7380 - val_loss: 1.3170 - val_accuracy: 0.7402\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 1.2048 - accuracy: 0.7473 - val_loss: 1.3513 - val_accuracy: 0.7297\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 1.1991 - accuracy: 0.7477 - val_loss: 1.3375 - val_accuracy: 0.7293\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.1829 - accuracy: 0.7496 - val_loss: 1.4529 - val_accuracy: 0.7148\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 1.1451 - accuracy: 0.7546 - val_loss: 1.3509 - val_accuracy: 0.7298\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 34s 336ms/step - loss: 1.1341 - accuracy: 0.7584 - val_loss: 1.3503 - val_accuracy: 0.7338\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 40s 401ms/step - loss: 1.1274 - accuracy: 0.7561 - val_loss: 1.2881 - val_accuracy: 0.7446\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 38s 384ms/step - loss: 1.1058 - accuracy: 0.7589 - val_loss: 1.2452 - val_accuracy: 0.7428\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 35s 349ms/step - loss: 1.0865 - accuracy: 0.7642 - val_loss: 1.2197 - val_accuracy: 0.7497\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 1.0650 - accuracy: 0.7707 - val_loss: 1.2605 - val_accuracy: 0.7475\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 1.0677 - accuracy: 0.7672 - val_loss: 1.2522 - val_accuracy: 0.7496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7e22a6e90>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds.repeat(), epochs=30, steps_per_epoch=100, validation_data=val_ds, validation_steps=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 21:52:24.706814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype int64\n",
      "\t [[{{node Placeholder/_12}}]]\n"
     ]
    }
   ],
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_context = model.encoder(ex_context_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token, done, state = model.get_initial_state(ex_context)\n",
    "tokens = []\n",
    "\n",
    "for n in range(10):\n",
    "    next_token, done, state = model.get_next_token(\n",
    "        ex_context, next_token, done, state)\n",
    "    tokens.append(next_token)\n",
    "\n",
    "tokens = tf.concat(tokens, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(tokens, language):\n",
    "    words = id_to_word_eng(tokens) if language==\"eng\" else id_to_word_spa(tokens)\n",
    "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "    result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "    result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "    return result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'tom would never be too surprised if mary behaves among',\n",
       "       b'why are you eating vegetables ?    ',\n",
       "       b'the child cant power tom watches for ten minutes .',\n",
       "       b'the poor woman woman beyond money .   ',\n",
       "       b'she took another book off the shelf .  ',\n",
       "       b'by the time [UNK] is coming to japan . ',\n",
       "       b'i cant play the piano .    ', b'dont be thankful .      ',\n",
       "       b'she scolded a sweater for her father .  ',\n",
       "       b'ill take this .      ', b'i no mind .      ',\n",
       "       b'i need one more .     ', b'could i open the door ?    ',\n",
       "       b'to translate it worse .     ',\n",
       "       b'those ok went to set pouring yesterday .  ',\n",
       "       b'that knife tastes good .     ', b'they are on ten oclock .    ',\n",
       "       b'everyone and tom is to arrest tom .  ',\n",
       "       b'in swimming . we have fun .   ', b'shes also vegetarian .      ',\n",
       "       b'i had fun of them .    ',\n",
       "       b'what are you doing this afternoon ?   ',\n",
       "       b'how old do you have the children ?  ',\n",
       "       b'tom is a [UNK] , ok to happen ? ',\n",
       "       b'hes addicted to junk food .    ', b'take away .       ',\n",
       "       b'she took over my hand .    ',\n",
       "       b'mother teresa was a catholic catholic work and tidy entered',\n",
       "       b'i was around percent over the woods .  ',\n",
       "       b'that dog quickly .      ', b'i saw you last night .    ',\n",
       "       b'ive never hide it .     ',\n",
       "       b'i cant start the not all those commotion in the',\n",
       "       b'you arent old enough to go to all place to',\n",
       "       b'as soon as the region could . move , its',\n",
       "       b'the last time i went to china .  ',\n",
       "       b'i feel this sweater uneasy .    ',\n",
       "       b'that guy is walking on toes .   ',\n",
       "       b'tom is getting married .     ',\n",
       "       b'is she a watch passport ? yes , this is',\n",
       "       b'tom afternoon [UNK] .      ', b'what did you celebrate ?     ',\n",
       "       b'he accused her of stealing his money .  ',\n",
       "       b'actually really believed that tom werent true .  ',\n",
       "       b'it is too expensive !     ',\n",
       "       b'tom said that he didnt want anything to eat .',\n",
       "       b'tom isnt in his room .    ', b'im as rich as he does .   ',\n",
       "       b'do you live in ?     ', b'it happened to cigar .     ',\n",
       "       b'it was dark to the hotel arrived at it .',\n",
       "       b'tom tried to stop right .    ',\n",
       "       b'tom liked all the pizzas .    ',\n",
       "       b'i hope to go to extremes to eat . ', b'tom called me .      ',\n",
       "       b'tom liked australia .      ', b'can we come back now ?    ',\n",
       "       b'have an advice with tom .    ', b'i do [UNK] one .     ',\n",
       "       b'most of those people wont do that it . ',\n",
       "       b'will they remember you when you should come ? ',\n",
       "       b'i have two dogs and three dogs and six .',\n",
       "       b'the clearness of the explanation did wise .  ',\n",
       "       b'did you understand what he said ?   '], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_text(tokens, language=\"eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'tom no estaria demasiado sorprendido si maria [UNK] aceptar la oferta de trabajo .',\n",
       "       b'\\xc2\\xbf por que no comes vegetales ?',\n",
       "       b'ese nino es incapaz de [UNK] quieto durante diez minutos .',\n",
       "       b'a la pobre mujer mayor le robaron el dinero .',\n",
       "       b'ella saco un libro de la repisa .',\n",
       "       b'por fin la primavera ha llegado a esta parte de japon .',\n",
       "       b'no puedo tocar el piano .', b'no seas [UNK] .',\n",
       "       b'ella [UNK] un jersey para su padre .', b'lo tomare en cuenta .',\n",
       "       b'no me importa .', b'necesito uno mas .',\n",
       "       b'\\xc2\\xbf puedo abrir la puerta ?', b'un dia lo lamentaras .',\n",
       "       b'esos prisioneros fueron liberados ayer .',\n",
       "       b'ese cuchillo corta bien .', b'son las diez en punto .',\n",
       "       b'todos [UNK] a tom .', b'las apariencias enganan .',\n",
       "       b'tomas tambien es vegetariano .', b'nos divertimos con ellos .',\n",
       "       b'\\xc2\\xbf que estas haciendo a estas horas ?',\n",
       "       b'\\xc2\\xbf cuantos anos tienen los ninos ?',\n",
       "       b'tom es un [UNK] , \\xc2\\xbf a que si ?',\n",
       "       b'el es adicto a la comida chatarra .', b'[UNK] .',\n",
       "       b'ella lo tomo de la mano .',\n",
       "       b'la madre teresa era una monja catolica que vivio y trabajo en [UNK] , india .',\n",
       "       b'estaba dando vueltas por el bosque .',\n",
       "       b'ese perro corre muy rapido .', b'te vi ayer .',\n",
       "       b'nunca me he [UNK] dejarlo .',\n",
       "       b'no puedo seguir la pista de todos los cambios que se estan dando en el mundo de la investigacion del [UNK] .',\n",
       "       b'no tienes edad suficiente para ir sola a nadar .',\n",
       "       b'tan pronto como el barco comenzo a moverse , el se [UNK] .',\n",
       "       b'la ultima vez que fui a china visite [UNK] .',\n",
       "       b'lo siento , ese vuelo esta lleno .',\n",
       "       b'ese tipo esta andando de puntillas .',\n",
       "       b'tom esta [UNK] para casarse .',\n",
       "       b'\\xc2\\xbf ella compro un reloj ? si , asi es .',\n",
       "       b'tom se muere por empezar .', b'\\xc2\\xbf que [UNK] ?',\n",
       "       b'le acuso de haber robado su dinero .',\n",
       "       b'en realidad , nunca crei que tom fuera canadiense .',\n",
       "       b'es demasiado caro !', b'tom dijo que no queria nada de comer .',\n",
       "       b'tom no esta en su habitacion .', b'soy tan rico como el .',\n",
       "       b'\\xc2\\xbf vives sola ?', b'ocurrio en [UNK] .',\n",
       "       b'estaba oscuro para cuando llegamos al hotel .',\n",
       "       b'tom trato de [UNK] de hacer eso .',\n",
       "       b'tom se comio toda la pizza el solo .',\n",
       "       b'espero con ganas a ir a tu casa a comer .', b'me llamo tom .',\n",
       "       b'a tom le gustaba australia .',\n",
       "       b'\\xc2\\xbf podemos regresar ahora ?', b'pide consejo a tom .',\n",
       "       b'manana me voy a comprar un celular .',\n",
       "       b'la mayoria de la gente no lo haria asi .',\n",
       "       b'\\xc2\\xbf se te informo cuando debes venir ?',\n",
       "       b'tengo dos perros , tres gatos y seis [UNK] .',\n",
       "       b'la claridad de la explicacion lo [UNK] .',\n",
       "       b'\\xc2\\xbf entendiste lo que el dijo ?'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_text(ex_context_tok,language=\"spa\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model in model.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
