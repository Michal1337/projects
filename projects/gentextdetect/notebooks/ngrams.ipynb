{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_paths(folder_path, recursive=False):\n",
    "    if recursive:\n",
    "        # Walk through all subdirectories\n",
    "        file_paths = [os.path.join(root, file) \n",
    "                      for root, _, files in os.walk(folder_path) \n",
    "                      for file in files if file.endswith('.csv')]\n",
    "    else:\n",
    "        # Get files in the root folder only\n",
    "        file_paths = [os.path.join(folder_path, file) \n",
    "                      for file in os.listdir(folder_path) \n",
    "                      if file.endswith('.csv')]\n",
    "    \n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ngrams(texts, min_n, max_n):\n",
    "    ngrams_frequencies = {}\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        words_only = [token for token in tokens if token.isalpha()]\n",
    "        \n",
    "        for n in range(min_n, max_n + 1):\n",
    "            if n not in ngrams_frequencies:\n",
    "                ngrams_frequencies[n] = Counter()\n",
    "            ngrams_generated = ngrams(words_only, n)\n",
    "            ngrams_frequencies[n].update(ngrams_generated)\n",
    "\n",
    "    return ngrams_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ngrams_to_csv(ngrams_frequencies, csv_filename):\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "\n",
    "        writer.writerow([\"n\", \"ngram\", \"frequency\"])\n",
    "\n",
    "        for n, counter in ngrams_frequencies.items():\n",
    "            sorted_ngrams = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "            for ngram, count in sorted_ngrams:\n",
    "                writer.writerow([n, \" \".join(ngram), count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUMAN_PATH = \"../data/data_human\"\n",
    "DATA_AI_PATH = \"../data/data_ai\"\n",
    "NGRAMS_PATH = \"../data/ngrams/\"\n",
    "MIN_N = 1\n",
    "MAX_N = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_csv_paths(DATA_HUMAN_PATH) + get_csv_paths(DATA_AI_PATH, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:07<00:00, 404.59it/s]\n",
      "100%|██████████| 3000/3000 [00:13<00:00, 228.03it/s]\n",
      "100%|██████████| 3000/3000 [00:04<00:00, 729.41it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 11196.73it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 3231.09it/s]\n",
      "100%|██████████| 3000/3000 [00:01<00:00, 2253.01it/s]\n",
      "100%|██████████| 3000/3000 [00:04<00:00, 679.56it/s] \n",
      "100%|██████████| 3000/3000 [00:00<00:00, 6316.19it/s]\n",
      "100%|██████████| 2638/2638 [00:27<00:00, 97.61it/s] \n",
      "100%|██████████| 384/384 [00:00<00:00, 423.33it/s]\n",
      "100%|██████████| 384/384 [00:00<00:00, 1182.84it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 305.94it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 3552.49it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 1257.95it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 3028.11it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 1244.39it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 660.13it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 473.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    if path.split(\"_\")[-1] == \"human.csv\":\n",
    "        ngrams_path = os.path.join(NGRAMS_PATH, path.split(\"/\")[-2], path.split(\"/\")[-1].replace(\".csv\", \"_ngrams.csv\"))\n",
    "    else:\n",
    "        ngrams_path = os.path.join(NGRAMS_PATH, path.split(\"/\")[-3], path.split(\"/\")[-2], path.split(\"/\")[-1].replace(\".csv\", \"_ngrams.csv\"))\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    texts = df[\"text\"].values[:3000]\n",
    "    ngrams_frequencies = calc_ngrams(texts, MIN_N, MAX_N)\n",
    "\n",
    "    save_ngrams_to_csv(ngrams_frequencies, ngrams_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
