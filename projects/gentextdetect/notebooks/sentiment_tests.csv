feature,data,model,u_statistic,p_value,significant
sentiment,nyt-comments,Qwen2.5-3B-Instruct,8822165689.5,0.0,True
sentiment,nyt-comments,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,9191994200.5,0.0,True
sentiment,nyt-comments,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,8551000573.5,0.0,True
sentiment,nyt-comments,Llama-3.1-8B-Instruct,9393543273.0,0.0,True
sentiment,nyt-comments,gpt-4.1-nano-2025-04-14,5750979719.0,0.0,True
sentiment,nyt-comments,Qwen2-72B-Instruct-AWQ,8059835936.5,0.0,True
sentiment,nyt-comments,Falcon3-7B-Instruct,5971075626.5,0.0,True
sentiment,nyt-comments,Phi-3-mini-128k-instruct,8170707070.5,0.0,True
sentiment,nyt-comments,phi-4,5865993038.0,0.0,True
sentiment,nyt-comments,Phi-3.5-mini-instruct,6896487226.5,0.0,True
sentiment,nyt-comments,Qwen2.5-72B-Instruct-AWQ,6652316582.0,0.0,True
sentiment,nyt-comments,Mistral-Nemo-Instruct-2407,6492748558.0,0.0,True
sentiment,nyt-comments,Llama-3.2-3B-Instruct,9581434602.0,0.0,True
sentiment,nyt-comments,Phi-3-medium-128k-instruct,5160297392.0,0.0,True
sentiment,nyt-comments,Ministral-8B-Instruct-2410,6848254713.5,0.0,True
sentiment,nyt-comments,Falcon3-3B-Instruct,6831588007.0,0.0,True
sentiment,nyt-comments,Qwen2.5-14B-Instruct,8234695375.0,0.0,True
sentiment,nyt-comments,Phi-4-mini-instruct,8255335336.5,0.0,True
sentiment,nyt-comments,Qwen2.5-7B-Instruct,8218680921.0,0.0,True
sentiment,nyt-comments,Phi-3-small-128k-instruct,5365366302.5,0.0,True
sentiment,nyt-comments,Qwen2-7B-Instruct,5412670934.5,0.0,True
sentiment,blogs,Qwen2.5-3B-Instruct,119369398.5,0.0,True
sentiment,blogs,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,65218582.0,0.0,True
sentiment,blogs,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,52239259.5,0.0,True
sentiment,blogs,Llama-3.1-8B-Instruct,47518242.0,0.0,True
sentiment,blogs,gpt-4.1-nano-2025-04-14,68471093.5,0.0,True
sentiment,blogs,Qwen2-72B-Instruct-AWQ,44886230.0,0.0,True
sentiment,blogs,Falcon3-7B-Instruct,95940157.5,0.0,True
sentiment,blogs,Phi-3-mini-128k-instruct,108343026.0,0.0,True
sentiment,blogs,phi-4,109952893.0,0.0,True
sentiment,blogs,Phi-3.5-mini-instruct,22468955.5,0.0,True
sentiment,blogs,Qwen2.5-72B-Instruct-AWQ,94547142.5,0.0,True
sentiment,blogs,Mistral-Nemo-Instruct-2407,119597711.0,0.0,True
sentiment,blogs,Llama-3.2-3B-Instruct,45074065.0,0.0,True
sentiment,blogs,Phi-3-medium-128k-instruct,62409583.0,0.0,True
sentiment,blogs,Ministral-8B-Instruct-2410,105533528.5,0.0,True
sentiment,blogs,Falcon3-3B-Instruct,53030143.5,0.0,True
sentiment,blogs,Qwen2.5-14B-Instruct,105943310.0,0.0,True
sentiment,blogs,Phi-4-mini-instruct,113338880.0,0.0,True
sentiment,blogs,Qwen2.5-7B-Instruct,87975757.5,0.0,True
sentiment,blogs,Phi-3-small-128k-instruct,45686818.5,0.0,True
sentiment,blogs,Qwen2-7B-Instruct,46313309.5,0.0,True
sentiment,raid,Qwen2.5-3B-Instruct,113314598.5,0.0,True
sentiment,raid,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,145275710.0,0.0,True
sentiment,raid,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,97848144.5,0.0,True
sentiment,raid,Llama-3.1-8B-Instruct,120105749.5,0.0,True
sentiment,raid,gpt-4.1-nano-2025-04-14,106466465.0,0.0,True
sentiment,raid,Qwen2-72B-Instruct-AWQ,74233165.5,0.0,True
sentiment,raid,Falcon3-7B-Instruct,64499304.0,0.0,True
sentiment,raid,Phi-3-mini-128k-instruct,47667463.0,0.0,True
sentiment,raid,phi-4,75718081.0,0.0,True
sentiment,raid,Phi-3.5-mini-instruct,28883802.5,0.0,True
sentiment,raid,Qwen2.5-72B-Instruct-AWQ,118188202.5,0.0,True
sentiment,raid,Mistral-Nemo-Instruct-2407,144287741.5,0.0,True
sentiment,raid,Llama-3.2-3B-Instruct,102857806.0,0.0,True
sentiment,raid,Phi-3-medium-128k-instruct,64605592.5,0.0,True
sentiment,raid,Ministral-8B-Instruct-2410,144936400.0,0.0,True
sentiment,raid,Falcon3-3B-Instruct,106385949.5,0.0,True
sentiment,raid,Qwen2.5-14B-Instruct,110818579.0,0.0,True
sentiment,raid,Phi-4-mini-instruct,72270067.5,0.0,True
sentiment,raid,Qwen2.5-7B-Instruct,75603957.0,0.0,True
sentiment,raid,Phi-3-small-128k-instruct,56023624.0,0.0,True
sentiment,raid,Qwen2-7B-Instruct,42419291.0,0.0,True
sentiment,natural-questions,Qwen2.5-3B-Instruct,19333867.0,0.03330889825662582,True
sentiment,natural-questions,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,17986762.5,1.0,False
sentiment,natural-questions,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,18044920.0,0.9999999999999998,False
sentiment,natural-questions,Llama-3.1-8B-Instruct,18621643.5,1.0,False
sentiment,natural-questions,gpt-4.1-nano-2025-04-14,18350375.5,0.9999996783558779,False
sentiment,natural-questions,Qwen2-72B-Instruct-AWQ,19190268.5,2.6880102032542543e-40,True
sentiment,natural-questions,Falcon3-7B-Instruct,17505902.5,2.688416735835758e-42,True
sentiment,natural-questions,Phi-3-mini-128k-instruct,17233382.0,0.742572598526057,False
sentiment,natural-questions,phi-4,19220744.0,8.880207332263458e-38,True
sentiment,natural-questions,Phi-3.5-mini-instruct,18219518.0,3.2986480334485524e-95,True
sentiment,natural-questions,Qwen2.5-72B-Instruct-AWQ,18115195.5,0.03719749285443024,True
sentiment,natural-questions,Mistral-Nemo-Instruct-2407,18496755.5,9.87967906498093e-153,True
sentiment,natural-questions,Llama-3.2-3B-Instruct,19877695.0,1.0,False
sentiment,natural-questions,Phi-3-medium-128k-instruct,16696867.0,6.703387476919348e-97,True
sentiment,natural-questions,Ministral-8B-Instruct-2410,17916365.5,1.5381888981434467e-79,True
sentiment,natural-questions,Falcon3-3B-Instruct,17547242.5,1.0500358931370747e-54,True
sentiment,natural-questions,Qwen2.5-14B-Instruct,20049696.0,6.431601681075947e-13,True
sentiment,natural-questions,Phi-4-mini-instruct,16732498.0,0.9999206069995952,False
sentiment,natural-questions,Qwen2.5-7B-Instruct,19209198.0,0.83878195878613,False
sentiment,natural-questions,Phi-3-small-128k-instruct,17800548.5,3.6254802820171255e-13,True
sentiment,natural-questions,Qwen2-7B-Instruct,17768431.0,6.753401759856841e-10,True
sentiment,writingprompts,Qwen2.5-3B-Instruct,33596259.0,0.0,True
sentiment,writingprompts,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,35560296.5,0.0,True
sentiment,writingprompts,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,35906055.0,0.0,True
sentiment,writingprompts,Llama-3.1-8B-Instruct,37951184.0,2.4382656503149505e-284,True
sentiment,writingprompts,gpt-4.1-nano-2025-04-14,40327460.5,1.6012616371628454e-218,True
sentiment,writingprompts,Qwen2-72B-Instruct-AWQ,24692290.5,0.0,True
sentiment,writingprompts,Falcon3-7B-Instruct,14301897.5,0.0,True
sentiment,writingprompts,Phi-3-mini-128k-instruct,11471370.0,0.0,True
sentiment,writingprompts,phi-4,17522241.0,0.0,True
sentiment,writingprompts,Phi-3.5-mini-instruct,10884203.5,0.0,True
sentiment,writingprompts,Qwen2.5-72B-Instruct-AWQ,22628340.0,0.0,True
sentiment,writingprompts,Mistral-Nemo-Instruct-2407,33045230.0,0.0,True
sentiment,writingprompts,Llama-3.2-3B-Instruct,39293548.5,1.255750109220748e-246,True
sentiment,writingprompts,Phi-3-medium-128k-instruct,16859636.5,0.0,True
sentiment,writingprompts,Ministral-8B-Instruct-2410,32166566.5,0.0,True
sentiment,writingprompts,Falcon3-3B-Instruct,15838114.5,0.0,True
sentiment,writingprompts,Qwen2.5-14B-Instruct,28381599.5,0.0,True
sentiment,writingprompts,Phi-4-mini-instruct,20338361.0,0.0,True
sentiment,writingprompts,Qwen2.5-7B-Instruct,26698985.0,0.0,True
sentiment,writingprompts,Phi-3-small-128k-instruct,14937621.0,0.0,True
sentiment,writingprompts,Qwen2-7B-Instruct,17219135.5,0.0,True
sentiment,essays,Qwen2.5-3B-Instruct,1776405.5,0.9705471333569626,False
sentiment,essays,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,1462179.5,2.1614522643294457e-10,True
sentiment,essays,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,1254810.0,7.978520695628306e-33,True
sentiment,essays,Llama-3.1-8B-Instruct,1477273.0,6.108690417378382e-09,True
sentiment,essays,gpt-4.1-nano-2025-04-14,516675.5,1.0493660600557476e-202,True
sentiment,essays,Qwen2-72B-Instruct-AWQ,1455318.5,2.5785559289217545e-09,True
sentiment,essays,Falcon3-7B-Instruct,1723011.5,0.6298771985123587,False
sentiment,essays,Phi-3-mini-128k-instruct,1580827.5,0.0005674485395092564,True
sentiment,essays,phi-4,1411314.0,3.1941567240219667e-10,True
sentiment,essays,Phi-3.5-mini-instruct,1716272.5,0.3888715323090317,False
sentiment,essays,Qwen2.5-72B-Instruct-AWQ,1136551.5,3.578250060888055e-46,True
sentiment,essays,Mistral-Nemo-Instruct-2407,1577082.5,0.0003573795522848729,True
sentiment,essays,Llama-3.2-3B-Instruct,1402846.5,8.556885048084547e-14,True
sentiment,essays,Phi-3-medium-128k-instruct,1148604.0,6.200070952626927e-47,True
sentiment,essays,Ministral-8B-Instruct-2410,1703512.5,0.9999769540093554,False
sentiment,essays,Falcon3-3B-Instruct,1581045.5,0.0046098523539627725,True
sentiment,essays,Qwen2.5-14B-Instruct,1664801.0,0.15631868949644756,False
sentiment,essays,Phi-4-mini-instruct,1839624.5,0.99999997302047,False
sentiment,essays,Qwen2.5-7B-Instruct,1344247.5,2.043794849910852e-15,True
sentiment,essays,Phi-3-small-128k-instruct,1762926.5,0.9533430674533943,False
sentiment,essays,Qwen2-7B-Instruct,1488084.0,1.185541624190435e-07,True
sentiment,nyt-articles,Qwen2.5-3B-Instruct,25163847.0,0.0,True
sentiment,nyt-articles,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,30884690.5,0.0,True
sentiment,nyt-articles,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,28125339.0,0.0,True
sentiment,nyt-articles,Llama-3.1-8B-Instruct,30517585.5,0.0,True
sentiment,nyt-articles,gpt-4.1-nano-2025-04-14,15877070.5,0.0,True
sentiment,nyt-articles,Qwen2-72B-Instruct-AWQ,28057729.5,0.0,True
sentiment,nyt-articles,Falcon3-7B-Instruct,16604315.5,0.0,True
sentiment,nyt-articles,Phi-3-mini-128k-instruct,17920657.0,0.0,True
sentiment,nyt-articles,phi-4,19175244.5,0.0,True
sentiment,nyt-articles,Phi-3.5-mini-instruct,16789219.0,0.0,True
sentiment,nyt-articles,Qwen2.5-72B-Instruct-AWQ,22646936.5,0.0,True
sentiment,nyt-articles,Mistral-Nemo-Instruct-2407,27365174.5,0.0,True
sentiment,nyt-articles,Llama-3.2-3B-Instruct,35414020.5,0.0,True
sentiment,nyt-articles,Phi-3-medium-128k-instruct,21228338.5,0.0,True
sentiment,nyt-articles,Ministral-8B-Instruct-2410,22751314.0,0.0,True
sentiment,nyt-articles,Falcon3-3B-Instruct,13655346.5,0.0,True
sentiment,nyt-articles,Qwen2.5-14B-Instruct,24184867.5,0.0,True
sentiment,nyt-articles,Phi-4-mini-instruct,21819807.0,0.0,True
sentiment,nyt-articles,Qwen2.5-7B-Instruct,24625411.0,0.0,True
sentiment,nyt-articles,Phi-3-small-128k-instruct,17138311.0,0.0,True
sentiment,nyt-articles,Qwen2-7B-Instruct,19452740.5,0.0,True
sentiment,tweets,Qwen2.5-3B-Instruct,3266601609.0,0.0,True
sentiment,tweets,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,4531893918.0,5.812223999884934e-308,True
sentiment,tweets,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,4597209618.0,1.398115601657243e-256,True
sentiment,tweets,Llama-3.1-8B-Instruct,4010768549.0,0.0,True
sentiment,tweets,gpt-4.1-nano-2025-04-14,3360420725.0,0.0,True
sentiment,tweets,Qwen2-72B-Instruct-AWQ,3638723244.0,0.0,True
sentiment,tweets,Falcon3-7B-Instruct,3681445795.0,0.0,True
sentiment,tweets,Phi-3-mini-128k-instruct,3799358017.0,0.0,True
sentiment,tweets,phi-4,3576985676.0,0.0,True
sentiment,tweets,Phi-3.5-mini-instruct,3792872261.5,0.0,True
sentiment,tweets,Qwen2.5-72B-Instruct-AWQ,3655025689.5,0.0,True
sentiment,tweets,Mistral-Nemo-Instruct-2407,3685479508.5,0.0,True
sentiment,tweets,Llama-3.2-3B-Instruct,3875079919.5,0.0,True
sentiment,tweets,Phi-3-medium-128k-instruct,3172035327.0,0.0,True
sentiment,tweets,Ministral-8B-Instruct-2410,3301319187.5,0.0,True
sentiment,tweets,Falcon3-3B-Instruct,3211367605.0,0.0,True
sentiment,tweets,Qwen2.5-14B-Instruct,3505543551.5,0.0,True
sentiment,tweets,Phi-4-mini-instruct,3668568904.5,0.0,True
sentiment,tweets,Qwen2.5-7B-Instruct,3436537137.0,0.0,True
sentiment,tweets,Phi-3-small-128k-instruct,3585830514.5,0.0,True
sentiment,tweets,Qwen2-7B-Instruct,3552252310.5,0.0,True
sentiment,reddit,Qwen2.5-3B-Instruct,2451290084.0,0.0,True
sentiment,reddit,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,3032544535.0,0.0,True
sentiment,reddit,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,2938725409.0,0.0,True
sentiment,reddit,Llama-3.1-8B-Instruct,2723394764.0,0.0,True
sentiment,reddit,gpt-4.1-nano-2025-04-14,2068027444.5,0.0,True
sentiment,reddit,Qwen2-72B-Instruct-AWQ,2183015128.0,0.0,True
sentiment,reddit,Falcon3-7B-Instruct,2310246517.0,0.0,True
sentiment,reddit,Phi-3-mini-128k-instruct,1926803353.5,0.0,True
sentiment,reddit,phi-4,1483675162.5,0.0,True
sentiment,reddit,Phi-3.5-mini-instruct,1175572612.5,0.0,True
sentiment,reddit,Qwen2.5-72B-Instruct-AWQ,2326357517.0,0.0,True
sentiment,reddit,Mistral-Nemo-Instruct-2407,2541767705.0,0.0,True
sentiment,reddit,Llama-3.2-3B-Instruct,2899583474.0,0.0,True
sentiment,reddit,Phi-3-medium-128k-instruct,1433585827.0,0.0,True
sentiment,reddit,Ministral-8B-Instruct-2410,2129664415.5,0.0,True
sentiment,reddit,Falcon3-3B-Instruct,1798614180.5,0.0,True
sentiment,reddit,Qwen2.5-14B-Instruct,2254504572.0,0.0,True
sentiment,reddit,Phi-4-mini-instruct,2175258776.0,0.0,True
sentiment,reddit,Qwen2.5-7B-Instruct,2201554606.0,0.0,True
sentiment,reddit,Phi-3-small-128k-instruct,2087011520.0,0.0,True
sentiment,reddit,Qwen2-7B-Instruct,1334520587.0,0.0,True
sentiment,xsum,Qwen2.5-3B-Instruct,223067201.5,2.1365628654795885e-281,True
sentiment,xsum,Meta-Llama-3.1-70B-Instruct-AWQ-INT4,175129060.5,0.0,True
sentiment,xsum,Meta-Llama-3.3-70B-Instruct-AWQ-INT4,156612177.5,0.0,True
sentiment,xsum,Llama-3.1-8B-Instruct,181478395.0,0.0,True
sentiment,xsum,gpt-4.1-nano-2025-04-14,167704418.5,0.0,True
sentiment,xsum,Qwen2-72B-Instruct-AWQ,126051757.0,0.0,True
sentiment,xsum,Falcon3-7B-Instruct,98867593.0,0.0,True
sentiment,xsum,Phi-3-mini-128k-instruct,91064901.0,0.0,True
sentiment,xsum,phi-4,74637703.5,0.0,True
sentiment,xsum,Phi-3.5-mini-instruct,73627413.0,0.0,True
sentiment,xsum,Qwen2.5-72B-Instruct-AWQ,117481247.5,0.0,True
sentiment,xsum,Mistral-Nemo-Instruct-2407,271100726.5,1.75504877110683e-19,True
sentiment,xsum,Llama-3.2-3B-Instruct,181009110.5,0.0,True
sentiment,xsum,Phi-3-medium-128k-instruct,284751605.0,0.08920920037950947,False
sentiment,xsum,Ministral-8B-Instruct-2410,294941343.0,0.999991893059197,False
sentiment,xsum,Falcon3-3B-Instruct,82756975.5,0.0,True
sentiment,xsum,Qwen2.5-14B-Instruct,109430359.5,0.0,True
sentiment,xsum,Phi-4-mini-instruct,129612709.0,0.0,True
sentiment,xsum,Qwen2.5-7B-Instruct,137524665.5,0.0,True
sentiment,xsum,Phi-3-small-128k-instruct,135054750.0,0.0,True
sentiment,xsum,Qwen2-7B-Instruct,89205000.0,0.0,True
