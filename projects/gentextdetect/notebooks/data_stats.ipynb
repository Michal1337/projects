{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"o200k_base\") #cl100k_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_paths(folder_path, recursive=False):\n",
    "    if recursive:\n",
    "        # Walk through all subdirectories\n",
    "        file_paths = [os.path.join(root, file) \n",
    "                      for root, _, files in os.walk(folder_path) \n",
    "                      for file in files if file.endswith('.csv')]\n",
    "    else:\n",
    "        # Get files in the root folder only\n",
    "        file_paths = [os.path.join(folder_path, file) \n",
    "                      for file in os.listdir(folder_path) \n",
    "                      if file.endswith('.csv')]\n",
    "    \n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(texts):\n",
    "    results = []\n",
    "    total_sentences, total_words, total_chars, total_tokens = 0, 0, 0, 0\n",
    "    total_samples = len(texts)\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "        text_words = 0\n",
    "        text_chars = 0\n",
    "        text_tokens = enc.encode(text)\n",
    "        sentences = sent_tokenize(text)\n",
    "        for sentence in sentences:\n",
    "            words = word_tokenize(sentence)\n",
    "            text_words += len(words)\n",
    "            text_chars += sum([len(word) for word in words])\n",
    "\n",
    "        total_sentences += len(sentences)\n",
    "        total_words += text_words\n",
    "        total_chars += text_chars\n",
    "        total_tokens += len(text_tokens)\n",
    "\n",
    "        results.append([len(sentences), text_words, text_chars, len(text_tokens)])\n",
    "    return results, total_samples, total_sentences, total_words, total_chars, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUMAN_PATH = \"../data/data_human/\"\n",
    "DATA_AI_PATH = \"../data/data_ai/\"\n",
    "STATS_PATH = \"../data/stats/\"\n",
    "MASTER_STATS_PATH = \"../data/stats/data_stats_master.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/data_human/blogs_human.csv',\n",
       " '../data/data_human/nyt-articles_human.csv',\n",
       " '../data/data_human/essays_human.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = get_csv_paths(DATA_HUMAN_PATH)\n",
    "paths[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/data_human/blogs_human.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576774/576774 [21:10<00:00, 454.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/data_human/nyt-articles_human.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15813/15813 [00:03<00:00, 4750.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/data_human/essays_human.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2638/2638 [00:13<00:00, 191.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# with open(MASTER_STATS_PATH, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow([\"data\", \"model\", \"num_samples\", \"num_sentences\", \"num_words\", \"num_chars\", \"num_tokens\"])\n",
    "\n",
    "for path in paths[-3:]:\n",
    "    print(path)\n",
    "    if path.split(\"_\")[-1] == \"human.csv\":\n",
    "        stats_path = os.path.join(STATS_PATH, path.split(\"/\")[-2], path.split(\"/\")[-1].replace(\".csv\", \"_stats.csv\"))\n",
    "    else:\n",
    "        stats_path = os.path.join(STATS_PATH, path.split(\"/\")[-3], path.split(\"/\")[-2], path.split(\"/\")[-1].replace(\".csv\", \"_stats.csv\"))\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        texts = df[\"text\"].values\n",
    "\n",
    "        results, num_samples, num_sentences, num_words, num_chars, num_tokens = calc_stats(texts)\n",
    "\n",
    "        results = pd.DataFrame(results, columns=[\"num_sentences\", \"num_words\", \"num_chars\", \"num_tokens\"])\n",
    "        results.to_csv(stats_path, index=False)\n",
    "\n",
    "        data_name, model = path.split(\"/\")[-1].split(\"_\")\n",
    "        model = model.removesuffix(\".csv\")\n",
    "\n",
    "        with open(MASTER_STATS_PATH, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([data_name, model, num_samples, num_sentences, num_words, num_chars, num_tokens])\n",
    "    except:\n",
    "        print(f\"Error processing {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
