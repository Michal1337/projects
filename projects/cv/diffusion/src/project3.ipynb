{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion - Image generation with diffusion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "! pip install numpy\n",
    "! pip install matplotlib\n",
    "! pip install seaborn\n",
    "! pip install scikit-learn\n",
    "! pip install scikit-image\n",
    "! pip install scipy\n",
    "\n",
    "! pip install tensorflow --upgrade\n",
    "! pip install tensorflow-io\n",
    "! pip install keras --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please read the guidelines on https://www.kaggle.com/docs/api#authentication\n",
    "# to get an idea where to put your kaggle API token to be able to download the dataset\n",
    "\n",
    "! pip install kaggle\n",
    "! kaggle datasets download -d jhoward/lsun_bedroom\n",
    "\n",
    "! unzip lsun_bedroom.zip -d data/\n",
    "! rm lsun_bedroom.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras.applications import InceptionV3\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from scipy import linalg\n",
    "from skimage.transform import resize\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sample/data0/lsun/bedroom\")\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_variables = {  # Interesting parameters I might want to change later\n",
    "    # One of \"grayscale\", \"rgb\", \"rgba\". Defaults to \"rgb\". Whether the images will be converted to have 1, 3, or 4 channels.\n",
    "    \"color_mode\": \"rgb\",\n",
    "    # Size of the batches of data. Defaults to 32. If None, the data will not be batched (the dataset will yield individual samples).\n",
    "    \"batch_size\": 32,\n",
    "    # Size to resize images to after they are read from disk, specified as (height, width). Defaults to (256, 256).\n",
    "    \"image_size\": (256, 256),\n",
    "    \"labels\": None,  # no labels\n",
    "    # Whether to shuffle the data. Defaults to True. If set to False, sorts the data in alphanumeric order.\n",
    "    \"shuffle\": True\n",
    "}\n",
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    **dataset_variables,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fr√©chet Inception Distance (FID)\n",
    "Introduced by Heusel et al. (https://arxiv.org/abs/1706.08500). We adapt their reference implementation which is available at https://github.com/bioinf-jku/TTUR/blob/master/fid.py. We also use code from https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Heusel et al.\n",
    "# For computing the FID, we propagated all images from the training dataset through the pretrained\n",
    "# Inception-v3 model following the computation of the Inception Score [53], however, we use the last\n",
    "# pooling layer as coding layer. For this coding layer, we calculated the mean mw and the covariance matrix Cw.\n",
    "inception_input_shape = (75, 75, 3)\n",
    "inception_model = InceptionV3(\n",
    "    include_top=False, pooling='avg', input_shape=inception_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input preprocessing\n",
    "def frechet_image_preprocessing(images):\n",
    "    prepressed = keras.applications.inception_v3.preprocess_input(\n",
    "        images.astype(\"float32\"))\n",
    "    resized = np.asarray(\n",
    "        [resize(image, inception_input_shape, 0) for image in prepressed])\n",
    "    return resized\n",
    "\n",
    "def get_mu_sigma(prediction):\n",
    "    mu =  prediction.mean(axis=0)\n",
    "    sigma = np.cov(prediction, rowvar=False)\n",
    "    return mu, sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function inspired from https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/\n",
    "def frechet_distance(images1, images2, model):\n",
    "    # calculate activations\n",
    "    pred1 = model.predict(frechet_image_preprocessing(images1))\n",
    "    mu1, sigma1 = get_mu_sigma(pred1)\n",
    "    pred2 = model.predict(frechet_image_preprocessing(images2))\n",
    "    mu2, sigma2 = get_mu_sigma(pred2)\n",
    "    \n",
    "    return calculate_frechet_distance(mu1, sigma1, mu2, sigma2)\n",
    "\n",
    "# From https://github.com/bioinf-jku/TTUR/blob/master/fid.py\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\n",
    "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
    "    and X_2 ~ N(mu_2, C_2) is\n",
    "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
    "\n",
    "    Stable version by Dougal J. Sutherland.\n",
    "\n",
    "    Params:\n",
    "    -- mu1 : Numpy array containing the activations of the pool_3 layer of the\n",
    "             inception net ( like returned by the function 'get_predictions')\n",
    "             for generated samples.\n",
    "    -- mu2   : The sample mean over activations of the pool_3 layer, precalcualted\n",
    "               on an representive data set.\n",
    "    -- sigma1: The covariance matrix over activations of the pool_3 layer for\n",
    "               generated samples.\n",
    "    -- sigma2: The covariance matrix over activations of the pool_3 layer,\n",
    "               precalcualted on an representive data set.\n",
    "\n",
    "    Returns:\n",
    "    --   : The Frechet Distance.\n",
    "    \"\"\"\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \"Training and test mean vectors have different lengths\"\n",
    "    assert sigma1.shape == sigma2.shape, \"Training and test covariances have different dimensions\"\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    # product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = \"fid calculation produces singular product; adding %s to diagonal of cov estimates\" % eps\n",
    "        warnings.warn(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    # numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError(\"Imaginary component {}\".format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: From the properties of the dot product, we know that the dot product of a vector with itself if the squared euclidian norm (https://math.libretexts.org/Bookshelves/Calculus/Calculus_(OpenStax)/12%3A_Vectors_in_Space/12.03%3A_The_Dot_Product#Properties_of_the_Dot_Product)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
