{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_world.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energia grupowana po regionie i czasie + informacje o regionie. LSTM, Dense, XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1930-12-08T08:01:02.000Z</td>\n",
       "      <td>23.261</td>\n",
       "      <td>120.277</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>mw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-05-13T18:52:43.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1930-12-03T18:51:47.000Z</td>\n",
       "      <td>18.233</td>\n",
       "      <td>96.298</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>mw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-05-13T18:52:43.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1930-12-02T07:01:30.000Z</td>\n",
       "      <td>25.854</td>\n",
       "      <td>98.356</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>mw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-05-13T18:52:43.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1930-11-28T07:32:56.000Z</td>\n",
       "      <td>18.779</td>\n",
       "      <td>-106.767</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>mw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-05-13T18:52:43.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1930-11-25T19:02:53.000Z</td>\n",
       "      <td>35.050</td>\n",
       "      <td>139.129</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>mw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-05-13T18:52:43.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  latitude  longitude  depth  mag magType  nst  \\\n",
       "0  1930-12-08T08:01:02.000Z    23.261    120.277   15.0  6.3      mw  NaN   \n",
       "1  1930-12-03T18:51:47.000Z    18.233     96.298   10.0  7.4      mw  NaN   \n",
       "2  1930-12-02T07:01:30.000Z    25.854     98.356   35.0  6.2      mw  NaN   \n",
       "3  1930-11-28T07:32:56.000Z    18.779   -106.767   15.0  6.3      mw  NaN   \n",
       "4  1930-11-25T19:02:53.000Z    35.050    139.129   15.0  6.9      mw  NaN   \n",
       "\n",
       "   gap  dmin  rms  ...                   updated place type  horizontalError  \\\n",
       "0  NaN   NaN  NaN  ...  2015-05-13T18:52:43.000Z   NaN  NaN              NaN   \n",
       "1  NaN   NaN  NaN  ...  2015-05-13T18:52:43.000Z   NaN  NaN              NaN   \n",
       "2  NaN   NaN  NaN  ...  2015-05-13T18:52:43.000Z   NaN  NaN              NaN   \n",
       "3  NaN   NaN  NaN  ...  2015-05-13T18:52:43.000Z   NaN  NaN              NaN   \n",
       "4  NaN   NaN  NaN  ...  2015-05-13T18:52:43.000Z   NaN  NaN              NaN   \n",
       "\n",
       "   depthError  magError  magNst  status  locationSource  magSource  \n",
       "0         NaN       NaN     NaN     NaN             NaN        NaN  \n",
       "1         NaN       NaN     NaN     NaN             NaN        NaN  \n",
       "2         NaN       NaN     NaN     NaN             NaN        NaN  \n",
       "3         NaN       NaN     NaN     NaN             NaN        NaN  \n",
       "4         NaN       NaN     NaN     NaN             NaN        NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/data_world.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"time\", \"latitude\", \"longitude\", \"mag\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>mag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1930-12-08 08:01:02.000</td>\n",
       "      <td>23.2610</td>\n",
       "      <td>120.2770</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1930-12-03 18:51:47.000</td>\n",
       "      <td>18.2330</td>\n",
       "      <td>96.2980</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1930-12-02 07:01:30.000</td>\n",
       "      <td>25.8540</td>\n",
       "      <td>98.3560</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1930-11-28 07:32:56.000</td>\n",
       "      <td>18.7790</td>\n",
       "      <td>-106.7670</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1930-11-25 19:02:53.000</td>\n",
       "      <td>35.0500</td>\n",
       "      <td>139.1290</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797041</th>\n",
       "      <td>2018-09-01 01:14:38.230</td>\n",
       "      <td>-30.4830</td>\n",
       "      <td>-177.9279</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797042</th>\n",
       "      <td>2018-09-01 01:07:59.120</td>\n",
       "      <td>-10.7558</td>\n",
       "      <td>124.3621</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797043</th>\n",
       "      <td>2018-09-01 01:00:13.810</td>\n",
       "      <td>-5.5167</td>\n",
       "      <td>147.1735</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797044</th>\n",
       "      <td>2018-09-01 00:27:11.440</td>\n",
       "      <td>46.8819</td>\n",
       "      <td>155.6566</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797045</th>\n",
       "      <td>2018-09-01 00:00:47.980</td>\n",
       "      <td>-55.7508</td>\n",
       "      <td>-28.3561</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>797046 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time  latitude  longitude  mag\n",
       "0      1930-12-08 08:01:02.000   23.2610   120.2770  6.3\n",
       "1      1930-12-03 18:51:47.000   18.2330    96.2980  7.4\n",
       "2      1930-12-02 07:01:30.000   25.8540    98.3560  6.2\n",
       "3      1930-11-28 07:32:56.000   18.7790  -106.7670  6.3\n",
       "4      1930-11-25 19:02:53.000   35.0500   139.1290  6.9\n",
       "...                        ...       ...        ...  ...\n",
       "797041 2018-09-01 01:14:38.230  -30.4830  -177.9279  4.3\n",
       "797042 2018-09-01 01:07:59.120  -10.7558   124.3621  4.0\n",
       "797043 2018-09-01 01:00:13.810   -5.5167   147.1735  4.6\n",
       "797044 2018-09-01 00:27:11.440   46.8819   155.6566  4.3\n",
       "797045 2018-09-01 00:00:47.980  -55.7508   -28.3561  4.8\n",
       "\n",
       "[797046 rows x 4 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"time\"] = pd.to_datetime(df[\"time\"], format=\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cut = dt.datetime(1973, 1, 1)\n",
    "df = df[df[\"time\"] > time_cut]\n",
    "df[\"energy\"] = 10**(1.44*df[\"mag\"]+5.24)\n",
    "df[\"label\"] = np.where(df[\"mag\"] > 5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"time\"] = df[\"time\"].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_split = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"latitude\"] = (df[\"latitude\"] // geo_split).astype(int)\n",
    "df[\"latitude\"] = df[\"latitude\"] + np.abs(np.min(df[\"latitude\"]))\n",
    "\n",
    "df[\"longitude\"] = (df[\"longitude\"] // geo_split).astype(int)\n",
    "df[\"longitude\"] = df[\"longitude\"] + np.abs(np.min(df[\"longitude\"]))\n",
    "df[\"pos\"] = df[\"latitude\"].astype(str) + \"_\" + df[\"longitude\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_regions(df: pd.DataFrame, threshold: int) -> pd.DataFrame:\n",
    "    tmp = []\n",
    "    df_f = df[df[\"mag\"] >= 5]\n",
    "    df_agg = df_f.groupby([\"pos\"])[\"mag\"].count().reset_index()\n",
    "    for _, row in df_agg.iterrows():\n",
    "        if row[\"mag\"] >= threshold:\n",
    "            tmp.append(row[\"pos\"])\n",
    "    df = df[df[\"pos\"].isin(tmp)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 45\n",
    "df = filter_regions(df, th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>energy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>1974-04</td>\n",
       "      <td>1.037528e+13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>1974-05</td>\n",
       "      <td>3.772820e+12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>1976-10</td>\n",
       "      <td>1.419058e+12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>1977-05</td>\n",
       "      <td>1.060177e+13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>1978-04</td>\n",
       "      <td>1.976970e+12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80377</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>2018-05</td>\n",
       "      <td>2.703958e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80378</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>1.018591e+12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80379</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>2018-09</td>\n",
       "      <td>5.248075e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80380</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>5.248075e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80381</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>1.018591e+12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80382 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude     time        energy  label\n",
       "0            24        153  1974-04  1.037528e+13      1\n",
       "1            24        153  1974-05  3.772820e+12      0\n",
       "2            24        153  1976-10  1.419058e+12      0\n",
       "3            24        153  1977-05  1.060177e+13      1\n",
       "4            24        153  1978-04  1.976970e+12      0\n",
       "...         ...        ...      ...           ...    ...\n",
       "80377       149        162  2018-05  2.703958e+11      0\n",
       "80378       149        162  2018-06  1.018591e+12      0\n",
       "80379       149        162  2018-09  5.248075e+11      0\n",
       "80380       149        162  2018-10  5.248075e+11      0\n",
       "80381       149        162  2018-12  1.018591e+12      0\n",
       "\n",
       "[80382 rows x 5 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg = df.groupby([\"latitude\", \"longitude\", \"time\"]).agg({\"energy\": \"sum\", \"label\": \"max\"}).reset_index()\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(df_agg: pd.DataFrame, block_size: int) -> (pd.DataFrame, pd.DataFrame):\n",
    "    dfs_train, dfs_val = [], []\n",
    "    for i in df_agg[\"latitude\"].unique():\n",
    "        for j in df_agg[\"longitude\"].unique():\n",
    "            tmp = df_agg[(df_agg[\"latitude\"] == i) & (df_agg[\"longitude\"] == j)]\n",
    "            if len(tmp) > 1:\n",
    "                tmp = tmp.set_index(\"time\")\n",
    "                idx = pd.date_range(tmp.index.min(), tmp.index.max(), freq=\"MS\").strftime('%Y-%m')\n",
    "                tmp = tmp.reindex(idx, fill_value=0)\n",
    "                tmp.index.name = \"time\"\n",
    "                tmp[\"label\"] = tmp[\"label\"].shift(-1)\n",
    "                tmp[\"latitude\"] = i\n",
    "                tmp[\"longitude\"] = j\n",
    "                n = int(0.8 * len(tmp))\n",
    "                df_train = tmp[:n]\n",
    "                print(i,j,(df_train[\"energy\"] == 0).sum() / len(df_train))\n",
    "                df_val = tmp[n:]\n",
    "                scaler = MinMaxScaler()\n",
    "                df_train[\"energy\"] = scaler.fit_transform(df_train[[\"energy\"]])\n",
    "                df_val[\"energy\"] = scaler.transform(df_val[[\"energy\"]])\n",
    "                for idx in range(block_size):\n",
    "                    df_train[\"energy\" + str(idx)] = df_train[\"energy\"].shift(idx)\n",
    "                    df_val[\"energy\" + str(idx)] = df_val[\"energy\"].shift(idx)\n",
    "                dfs_train.append(df_train)\n",
    "                dfs_val.append(df_val)\n",
    "    df_final_train = pd.concat(dfs_train)\n",
    "    df_final_val = pd.concat(dfs_val)\n",
    "    return df_final_train, df_final_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 153 0.8787878787878788\n",
      "25 153 0.7231121281464531\n",
      "26 154 0.6819221967963387\n",
      "27 154 0.634090909090909\n",
      "28 153 0.6933638443935927\n",
      "28 154 0.8073394495412844\n",
      "28 152 0.5636363636363636\n",
      "29 153 0.7840909090909091\n",
      "29 152 0.5795454545454546\n",
      "29 151 0.8\n",
      "46 106 0.9227272727272727\n",
      "47 106 0.8590909090909091\n",
      "48 106 0.8758782201405152\n",
      "48 357 0.7624703087885986\n",
      "50 107 0.5844748858447488\n",
      "50 108 0.5023923444976076\n",
      "51 107 0.4470046082949309\n",
      "51 108 0.44874715261959\n",
      "51 0 0.6113636363636363\n",
      "51 1 0.6727272727272727\n",
      "52 108 0.3325740318906606\n",
      "52 0 0.6903669724770642\n",
      "52 1 0.6032110091743119\n",
      "53 108 0.45\n",
      "53 0 0.6450116009280742\n",
      "53 1 0.5694444444444444\n",
      "53 2 0.7136150234741784\n",
      "53 112 0.6866359447004609\n",
      "54 108 0.47165532879818595\n",
      "54 1 0.5194508009153318\n",
      "54 2 0.4590909090909091\n",
      "55 108 0.547945205479452\n",
      "55 1 0.6990740740740741\n",
      "55 2 0.5818181818181818\n",
      "55 3 0.7909090909090909\n",
      "56 2 0.726027397260274\n",
      "56 3 0.7454128440366973\n",
      "57 108 0.7522727272727273\n",
      "57 3 0.6628440366972477\n",
      "58 2 0.7695852534562212\n",
      "58 3 0.7928571428571428\n",
      "58 109 0.8337236533957846\n",
      "59 359 0.4783599088838269\n",
      "60 0 0.55125284738041\n",
      "60 3 0.7662037037037037\n",
      "60 109 0.8340909090909091\n",
      "60 359 0.36961451247165533\n",
      "60 4 0.8166666666666667\n",
      "60 113 0.40816326530612246\n",
      "61 0 0.36281179138321995\n",
      "61 2 0.773972602739726\n",
      "61 3 0.7912844036697247\n",
      "61 109 0.8263888888888888\n",
      "61 359 0.31363636363636366\n",
      "61 4 0.7064220183486238\n",
      "61 113 0.3704545454545455\n",
      "62 0 0.3931818181818182\n",
      "62 3 0.7162471395881007\n",
      "62 4 0.6912442396313364\n",
      "62 5 0.7795454545454545\n",
      "62 111 0.44545454545454544\n",
      "62 349 0.7611940298507462\n",
      "62 350 0.6227272727272727\n",
      "62 351 0.682983682983683\n",
      "63 0 0.3492063492063492\n",
      "63 1 0.45454545454545453\n",
      "63 3 0.7076566125290024\n",
      "63 4 0.8032407407407407\n",
      "63 5 0.6227272727272727\n",
      "63 111 0.3068181818181818\n",
      "63 349 0.6612529002320185\n",
      "63 350 0.6621315192743764\n",
      "63 348 0.87409200968523\n",
      "64 1 0.16363636363636364\n",
      "64 2 0.3470319634703196\n",
      "64 109 0.8443396226415094\n",
      "64 4 0.7488479262672811\n",
      "64 5 0.634703196347032\n",
      "64 111 0.5239179954441914\n",
      "64 349 0.546485260770975\n",
      "64 348 0.6880733944954128\n",
      "64 6 0.7215777262180975\n",
      "65 2 0.37272727272727274\n",
      "65 109 0.8458049886621315\n",
      "65 4 0.634090909090909\n",
      "65 349 0.4897959183673469\n",
      "65 348 0.6926605504587156\n",
      "65 6 0.7293577981651376\n",
      "65 110 0.6376146788990825\n",
      "65 347 0.8796296296296297\n",
      "66 1 0.3340909090909091\n",
      "66 2 0.44874715261959\n",
      "66 4 0.6940639269406392\n",
      "66 5 0.6529680365296804\n",
      "66 349 0.54337899543379\n",
      "66 348 0.5555555555555556\n",
      "66 6 0.7384259259259259\n",
      "66 110 0.6954545454545454\n",
      "66 347 0.764018691588785\n",
      "67 107 0.8678815489749431\n",
      "67 1 0.06575963718820861\n",
      "67 5 0.555045871559633\n",
      "67 348 0.7126168224299065\n",
      "67 6 0.6613636363636364\n",
      "67 347 0.47368421052631576\n",
      "67 7 0.7471526195899773\n",
      "68 106 0.7949886104783599\n",
      "68 2 0.695852534562212\n",
      "68 5 0.5379310344827586\n",
      "68 6 0.4489795918367347\n",
      "68 347 0.6620370370370371\n",
      "68 7 0.6224256292906178\n",
      "69 2 0.6973995271867612\n",
      "69 4 0.7545454545454545\n",
      "69 5 0.5568181818181818\n",
      "69 6 0.20408163265306123\n",
      "69 347 0.34467120181405897\n",
      "69 7 0.6651480637813212\n",
      "69 346 0.8333333333333334\n",
      "70 6 0.7808219178082192\n",
      "70 347 0.24263038548752835\n",
      "70 346 0.6788154897494305\n",
      "70 104 0.8120649651972158\n",
      "71 347 0.5318181818181819\n",
      "71 346 0.5863636363636363\n",
      "71 103 0.8581560283687943\n",
      "72 346 0.41818181818181815\n",
      "73 346 0.4159090909090909\n",
      "73 298 0.6794258373205742\n",
      "73 299 0.8471502590673575\n",
      "73 342 0.8435374149659864\n",
      "73 345 0.6619718309859155\n",
      "74 346 0.7625570776255708\n",
      "74 342 0.7954545454545454\n",
      "74 345 0.6674311926605505\n",
      "74 293 0.8726415094339622\n",
      "74 340 0.7954545454545454\n",
      "74 341 0.31519274376417233\n",
      "74 344 0.7522727272727273\n",
      "75 340 0.805045871559633\n",
      "75 287 0.8615023474178404\n",
      "75 288 0.8988235294117647\n",
      "75 297 0.8318181818181818\n",
      "75 338 0.8141176470588235\n",
      "75 339 0.7454128440366973\n",
      "76 296 0.8578947368421053\n",
      "76 301 0.7738927738927739\n",
      "76 303 0.7172897196261683\n",
      "76 304 0.6967418546365914\n",
      "76 337 0.839622641509434\n",
      "77 307 0.4872389791183295\n",
      "77 308 0.21363636363636362\n",
      "77 309 0.24193548387096775\n",
      "77 334 0.7477064220183486\n",
      "77 335 0.6319444444444444\n",
      "77 336 0.7066974595842956\n",
      "78 309 0.23582766439909297\n",
      "78 334 0.2636363636363636\n",
      "78 335 0.48847926267281105\n",
      "78 284 0.7831050228310502\n",
      "78 285 0.7178899082568807\n",
      "78 310 0.2191780821917808\n",
      "78 311 0.6810933940774487\n",
      "78 322 0.9127358490566038\n",
      "78 323 0.9116161616161617\n",
      "78 326 0.4396355353075171\n",
      "78 327 0.22727272727272727\n",
      "78 328 0.5818181818181818\n",
      "78 329 0.5941043083900227\n",
      "78 330 0.5545454545454546\n",
      "78 331 0.6349206349206349\n",
      "78 332 0.7699316628701595\n",
      "78 333 0.740909090909091\n",
      "79 334 0.4772727272727273\n",
      "79 284 0.8258823529411765\n",
      "79 310 0.5903890160183066\n",
      "79 326 0.3348519362186788\n",
      "79 327 0.2947845804988662\n",
      "79 328 0.6009174311926605\n",
      "79 329 0.6326530612244898\n",
      "79 330 0.528604118993135\n",
      "79 331 0.27045454545454545\n",
      "79 332 0.38095238095238093\n",
      "79 333 0.4013605442176871\n",
      "79 282 0.6160919540229886\n",
      "79 283 0.7293577981651376\n",
      "79 325 0.513953488372093\n",
      "80 309 0.7570093457943925\n",
      "80 331 0.5704545454545454\n",
      "80 332 0.35909090909090907\n",
      "80 333 0.4159090909090909\n",
      "80 282 0.5558086560364465\n",
      "80 283 0.768348623853211\n",
      "80 281 0.7832167832167832\n",
      "81 357 0.0\n",
      "81 307 0.7694117647058824\n",
      "81 309 0.6605504587155964\n",
      "81 310 0.639618138424821\n",
      "81 322 0.7481840193704601\n",
      "81 326 0.805045871559633\n",
      "81 328 0.8378378378378378\n",
      "81 330 0.8371559633027523\n",
      "81 331 0.7289293849658315\n",
      "81 325 0.7060185185185185\n",
      "81 281 0.8127853881278538\n",
      "81 280 0.8932038834951457\n",
      "81 315 0.7339449541284404\n",
      "81 319 0.6086956521739131\n",
      "81 320 0.7420091324200914\n",
      "82 281 0.8752834467120182\n",
      "82 319 0.5389908256880734\n",
      "82 279 0.9013761467889908\n",
      "82 318 0.5306122448979592\n",
      "82 321 0.7934272300469484\n",
      "83 307 0.8029556650246306\n",
      "83 279 0.816933638443936\n",
      "83 316 0.8738532110091743\n",
      "84 301 0.9097222222222222\n",
      "84 303 0.5977272727272728\n",
      "84 304 0.6227272727272727\n",
      "84 302 0.7413394919168591\n",
      "84 305 0.731651376146789\n",
      "84 312 0.8557692307692307\n",
      "84 313 0.8459657701711492\n",
      "85 303 0.5454545454545454\n",
      "85 302 0.6651480637813212\n",
      "85 305 0.6167800453514739\n",
      "85 277 0.8028169014084507\n",
      "85 306 0.5240274599542334\n",
      "86 303 0.7925\n",
      "86 307 0.4305555555555556\n",
      "86 308 0.7488479262672811\n",
      "86 302 0.7848699763593381\n",
      "86 277 0.7726218097447796\n",
      "86 306 0.3378684807256236\n",
      "86 300 0.8608923884514436\n",
      "87 307 0.6077981651376146\n",
      "87 308 0.3372093023255814\n",
      "87 306 0.3741496598639456\n",
      "87 275 0.7892156862745098\n",
      "87 276 0.7482678983833718\n",
      "88 308 0.6314496314496314\n",
      "88 306 0.4113636363636364\n",
      "89 307 0.6444954128440367\n",
      "89 305 0.6568181818181819\n",
      "89 306 0.5636363636363636\n",
      "89 275 0.7848970251716247\n",
      "90 307 0.6462585034013606\n",
      "90 305 0.5409090909090909\n",
      "90 306 0.3854875283446712\n",
      "90 97 0.7181818181818181\n",
      "90 274 0.7254901960784313\n",
      "91 106 0.2863636363636364\n",
      "91 303 0.7374429223744292\n",
      "91 305 0.7293577981651376\n",
      "91 306 0.41950113378684806\n",
      "92 303 0.8594470046082949\n",
      "92 306 0.545662100456621\n",
      "92 97 0.7591743119266054\n",
      "92 274 0.8173302107728337\n",
      "93 306 0.5230414746543779\n",
      "93 274 0.9108433734939759\n",
      "93 273 0.8103448275862069\n",
      "94 305 0.7096774193548387\n",
      "94 306 0.39090909090909093\n",
      "95 305 0.6944444444444444\n",
      "95 306 0.6013824884792627\n",
      "95 274 0.9354838709677419\n",
      "96 323 0.7736720554272517\n",
      "96 305 0.652073732718894\n",
      "96 92 0.6475972540045767\n",
      "96 93 0.4727272727272727\n",
      "97 323 0.5125858123569794\n",
      "97 321 0.8443396226415094\n",
      "97 305 0.672093023255814\n",
      "97 92 0.5547945205479452\n",
      "97 91 0.4659090909090909\n",
      "97 324 0.6045454545454545\n",
      "98 325 0.6818181818181818\n",
      "98 300 0.41723356009070295\n",
      "98 324 0.5102040816326531\n",
      "98 89 0.49658314350797267\n",
      "98 90 0.5102040816326531\n",
      "99 326 0.7798165137614679\n",
      "99 86 0.4851258581235698\n",
      "99 87 0.4269406392694064\n",
      "99 88 0.45681818181818185\n",
      "99 236 0.9135514018691588\n",
      "100 327 0.784037558685446\n",
      "100 85 0.5986238532110092\n",
      "101 300 0.8089330024813896\n",
      "101 81 0.4305239179954442\n",
      "103 326 0.694954128440367\n",
      "103 325 0.3492063492063492\n",
      "104 301 0.551487414187643\n",
      "106 301 0.6620370370370371\n",
      "106 323 0.551487414187643\n",
      "107 301 0.5743707093821511\n",
      "108 301 0.4302059496567506\n",
      "109 301 0.48863636363636365\n",
      "109 302 0.23853211009174313\n",
      "112 323 0.8851963746223565\n",
      "112 320 0.6095890410958904\n",
      "113 310 0.7365853658536585\n",
      "113 320 0.8454332552693209\n",
      "114 310 0.6045454545454545\n",
      "115 321 0.7425287356321839\n",
      "116 321 0.6840909090909091\n",
      "118 321 0.6227272727272727\n",
      "119 319 0.6894977168949772\n",
      "119 321 0.725\n",
      "119 253 0.8863109048723898\n",
      "120 319 0.6027397260273972\n",
      "120 320 0.3522727272727273\n",
      "120 321 0.591324200913242\n",
      "121 322 0.8142201834862385\n",
      "121 320 0.5045454545454545\n",
      "121 321 0.3877551020408163\n",
      "121 250 0.07709750566893424\n",
      "121 251 0.06802721088435375\n",
      "122 322 0.6439909297052154\n",
      "122 323 0.9111111111111111\n",
      "122 321 0.4875283446712018\n",
      "123 322 0.6795454545454546\n",
      "123 323 0.8554778554778555\n",
      "123 321 0.740909090909091\n",
      "124 322 0.7995444191343963\n",
      "124 323 0.6651376146788991\n",
      "124 253 0.775\n",
      "125 322 0.5899772209567198\n",
      "125 323 0.7299771167048055\n",
      "126 322 0.4113636363636364\n",
      "127 322 0.4680365296803653\n",
      "127 324 0.6804597701149425\n",
      "128 326 0.5170842824601367\n",
      "128 327 0.43863636363636366\n",
      "128 328 0.7579908675799086\n",
      "128 52 0.6013667425968109\n",
      "129 328 0.425\n",
      "129 329 0.48853211009174313\n",
      "129 330 0.8274231678486997\n",
      "129 50 0.6735632183908046\n",
      "130 330 0.6590389016018307\n",
      "130 331 0.7018348623853211\n",
      "131 334 0.8836633663366337\n",
      "131 332 0.6013667425968109\n",
      "131 333 0.6045454545454545\n",
      "132 334 0.7652582159624414\n",
      "133 334 0.6272727272727273\n",
      "134 335 0.6386363636363637\n",
      "134 336 0.7835990888382688\n",
      "136 0 0.5102040816326531\n",
      "136 1 0.42857142857142855\n",
      "136 2 0.6506849315068494\n",
      "136 3 0.4671201814058957\n",
      "136 359 0.5899772209567198\n",
      "136 4 0.5616438356164384\n",
      "136 5 0.6844660194174758\n",
      "136 6 0.6689497716894978\n",
      "136 339 0.8194444444444444\n",
      "136 358 0.5886363636363636\n",
      "137 340 0.7431192660550459\n",
      "137 339 0.6651162790697674\n",
      "137 10 0.5545454545454546\n",
      "137 11 0.5954545454545455\n",
      "138 340 0.6077981651376146\n",
      "138 341 0.8718535469107551\n",
      "139 341 0.7061503416856492\n",
      "149 162 0.9134396355353075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>energy</th>\n",
       "      <th>label</th>\n",
       "      <th>energy0</th>\n",
       "      <th>energy1</th>\n",
       "      <th>energy2</th>\n",
       "      <th>energy3</th>\n",
       "      <th>energy4</th>\n",
       "      <th>energy5</th>\n",
       "      <th>energy6</th>\n",
       "      <th>energy7</th>\n",
       "      <th>energy8</th>\n",
       "      <th>energy9</th>\n",
       "      <th>energy10</th>\n",
       "      <th>energy11</th>\n",
       "      <th>energy12</th>\n",
       "      <th>energy13</th>\n",
       "      <th>energy14</th>\n",
       "      <th>energy15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1974-04</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974-05</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974-06</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974-07</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974-08</th>\n",
       "      <td>24</td>\n",
       "      <td>153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-08</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10</th>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159643 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude    energy  label   energy0   energy1   energy2  \\\n",
       "time                                                                          \n",
       "1974-04        24        153  0.004837    0.0  0.004837       NaN       NaN   \n",
       "1974-05        24        153  0.001759    0.0  0.001759  0.004837       NaN   \n",
       "1974-06        24        153  0.000000    0.0  0.000000  0.001759  0.004837   \n",
       "1974-07        24        153  0.000000    0.0  0.000000  0.000000  0.001759   \n",
       "1974-08        24        153  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "...           ...        ...       ...    ...       ...       ...       ...   \n",
       "2009-06       149        162  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "2009-07       149        162  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "2009-08       149        162  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "2009-09       149        162  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "2009-10       149        162  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "          energy3   energy4   energy5   energy6   energy7  energy8  energy9  \\\n",
       "time                                                                          \n",
       "1974-04       NaN       NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "1974-05       NaN       NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "1974-06       NaN       NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "1974-07  0.004837       NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "1974-08  0.001759  0.004837       NaN       NaN       NaN      NaN      NaN   \n",
       "...           ...       ...       ...       ...       ...      ...      ...   \n",
       "2009-06  0.047918  0.000000  0.000000  0.000000  0.000000      0.0      0.0   \n",
       "2009-07  0.000000  0.047918  0.000000  0.000000  0.000000      0.0      0.0   \n",
       "2009-08  0.000000  0.000000  0.047918  0.000000  0.000000      0.0      0.0   \n",
       "2009-09  0.000000  0.000000  0.000000  0.047918  0.000000      0.0      0.0   \n",
       "2009-10  0.000000  0.000000  0.000000  0.000000  0.047918      0.0      0.0   \n",
       "\n",
       "         energy10  energy11  energy12  energy13  energy14  energy15  \n",
       "time                                                                 \n",
       "1974-04       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1974-05       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1974-06       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1974-07       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1974-08       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "...           ...       ...       ...       ...       ...       ...  \n",
       "2009-06       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2009-07       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2009-08       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2009-09       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2009-10       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[159643 rows x 20 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 16\n",
    "df_train, df_val = make_ds(df_agg, block_size)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "df_val.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    138906\n",
       "1.0     15202\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, n_embed, vocab_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.n_embed = n_embed\n",
    "        self.loc_emb_x = tf.keras.layers.Embedding(vocab_size, n_embed)\n",
    "        self.loc_emb_y = tf.keras.layers.Embedding(vocab_size, n_embed)\n",
    "        self.lstm1 = tf.keras.layers.LSTM(n_embed * 2, return_sequences=True)\n",
    "        self.lstm2 = tf.keras.layers.LSTM(n_embed)\n",
    "        self.dense_h = tf.keras.layers.Dense(2 * n_embed)\n",
    "        self.dense_c = tf.keras.layers.Dense(2 * n_embed)\n",
    "        self.dense = tf.keras.layers.Dense(n_embed, activation='relu')\n",
    "        self.conc = tf.keras.layers.Concatenate()\n",
    "        self.out = tf.keras.layers.Dense(2)\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        loc, timestep = inputs\n",
    "        x = self.loc_emb_x(loc[:, 0])\n",
    "        y = self.loc_emb_y(loc[:, 1])\n",
    "        x_loc = self.conc([x, y])\n",
    "        x_loc = tf.reshape(x_loc, [-1, 2 * self.n_embed])  \n",
    "        x_loc = tf.reshape(x_loc, [-1, 2 * self.n_embed])\n",
    "        h = self.dense_h(x_loc)\n",
    "        c = self.dense_c(x_loc)\n",
    "        x = self.lstm1(timestep, initial_state=[c, h])\n",
    "        x = self.lstm2(x)\n",
    "        x = self.dense(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop([\"label\", \"latitude\", \"longitude\", \"energy\"], axis=1).to_numpy()\n",
    "x_train = x_train.reshape(-1, block_size, 1)\n",
    "y_train = df_train[\"label\"].to_numpy().reshape(-1, 1)\n",
    "x_val = df_val.drop([\"label\", \"latitude\", \"longitude\", \"energy\"], axis=1).to_numpy()\n",
    "x_val = x_val.reshape(-1, block_size, 1)\n",
    "y_val = df_val[\"label\"].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013548939704623"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate balance of classes\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "counts[0] / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos_train = df_train[[\"latitude\", \"longitude\"]].to_numpy()\n",
    "x_pos_val = df_val[[\"latitude\", \"longitude\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add anoother column whith 1 - label\n",
    "y_train = np.concatenate((y_train, 1 - y_train), axis=1)\n",
    "y_val = np.concatenate((y_val, 1 - y_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 256\n",
    "vocab_size = 2000\n",
    "model = MyModel(n_embed, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy', tf.keras.metrics.F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 23s 199ms/step - loss: 0.3436 - accuracy: 0.9001 - f1_score: 0.4746 - val_loss: 0.3029 - val_accuracy: 0.9066 - val_f1_score: 0.4909\n",
      "Epoch 2/20\n",
      "76/76 [==============================] - 16s 210ms/step - loss: 0.3099 - accuracy: 0.9014 - f1_score: 0.4741 - val_loss: 0.3079 - val_accuracy: 0.9028 - val_f1_score: 0.5001\n",
      "Epoch 3/20\n",
      "76/76 [==============================] - 26s 341ms/step - loss: 0.3093 - accuracy: 0.9014 - f1_score: 0.4741 - val_loss: 0.3041 - val_accuracy: 0.9037 - val_f1_score: 0.4992\n",
      "Epoch 4/20\n",
      "76/76 [==============================] - 30s 391ms/step - loss: 0.3093 - accuracy: 0.9014 - f1_score: 0.4741 - val_loss: 0.3020 - val_accuracy: 0.9074 - val_f1_score: 0.4757\n",
      "Epoch 5/20\n",
      "76/76 [==============================] - 17s 224ms/step - loss: 0.3081 - accuracy: 0.9013 - f1_score: 0.4743 - val_loss: 0.3073 - val_accuracy: 0.9074 - val_f1_score: 0.4757\n",
      "Epoch 6/20\n",
      "27/76 [=========>....................] - ETA: 11s - loss: 0.3109 - accuracy: 0.9001 - f1_score: 0.4737"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/majkel/eq_prediction/notebooks/data_world_dataset/simple_model_v2.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/majkel/eq_prediction/notebooks/data_world_dataset/simple_model_v2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit([x_pos_train, x_train], y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m([x_pos_val, x_val], y_val))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.fit([x_pos_train, x_train], y_train, epochs=20, batch_size=2048, validation_data=([x_pos_val, x_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, n_embed, vocab_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.n_embed = n_embed\n",
    "        self.loc_emb_h = tf.keras.layers.Embedding(vocab_size, n_embed)\n",
    "        self.loc_emb_c = tf.keras.layers.Embedding(vocab_size, n_embed)\n",
    "        self.lstm1 = tf.keras.layers.LSTM(n_embed * 2, return_sequences=True)\n",
    "        self.lstm2 = tf.keras.layers.LSTM(n_embed * 2)\n",
    "        self.dense = tf.keras.layers.Dense(n_embed, activation='relu')\n",
    "        self.out = tf.keras.layers.Dense(2)\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        loc, timestep = inputs\n",
    "        h = self.loc_emb_h(loc)\n",
    "        c = self.loc_emb_c(loc)\n",
    "        # reshape h and c to (batch_size, n_embed)\n",
    "        h = tf.reshape(h, [-1, 2 * self.n_embed])\n",
    "        c = tf.reshape(c, [-1, 2 * self.n_embed])\n",
    "        x = self.lstm1(timestep, initial_state=[c, h])\n",
    "        x = self.lstm2(x, initial_state=[c, h])\n",
    "        x = self.dense(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 256\n",
    "vocab_size = 2000\n",
    "model = MyModel(n_embed, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy', tf.keras.metrics.F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 20:09:23.402333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /home/majkel/miniconda3/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2023-09-21 20:09:24.129018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3e6b57f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-21 20:09:24.129172: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060 with Max-Q Design, Compute Capability 7.5\n",
      "2023-09-21 20:09:24.414868: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-21 20:09:25.767611: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 224s 633ms/step - loss: 0.2864 - accuracy: 0.8969 - f1_score: 0.6347 - val_loss: 0.2582 - val_accuracy: 0.9037 - val_f1_score: 0.6943\n",
      "Epoch 2/20\n",
      "329/329 [==============================] - 244s 743ms/step - loss: 0.2342 - accuracy: 0.9151 - f1_score: 0.7466 - val_loss: 0.2432 - val_accuracy: 0.9072 - val_f1_score: 0.7338\n",
      "Epoch 3/20\n",
      "329/329 [==============================] - 133s 404ms/step - loss: 0.2224 - accuracy: 0.9171 - f1_score: 0.7581 - val_loss: 0.2371 - val_accuracy: 0.9084 - val_f1_score: 0.7401\n",
      "Epoch 4/20\n",
      "329/329 [==============================] - 50s 151ms/step - loss: 0.2163 - accuracy: 0.9183 - f1_score: 0.7575 - val_loss: 0.2419 - val_accuracy: 0.9086 - val_f1_score: 0.7294\n",
      "Epoch 5/20\n",
      "329/329 [==============================] - 39s 119ms/step - loss: 0.2125 - accuracy: 0.9187 - f1_score: 0.7580 - val_loss: 0.2262 - val_accuracy: 0.9102 - val_f1_score: 0.7631\n",
      "Epoch 6/20\n",
      "329/329 [==============================] - 57s 174ms/step - loss: 0.2089 - accuracy: 0.9198 - f1_score: 0.7601 - val_loss: 0.2322 - val_accuracy: 0.9104 - val_f1_score: 0.7391\n",
      "Epoch 7/20\n",
      "329/329 [==============================] - 40s 121ms/step - loss: 0.2077 - accuracy: 0.9203 - f1_score: 0.7596 - val_loss: 0.2310 - val_accuracy: 0.9094 - val_f1_score: 0.7466\n",
      "Epoch 8/20\n",
      "329/329 [==============================] - 41s 125ms/step - loss: 0.2069 - accuracy: 0.9201 - f1_score: 0.7600 - val_loss: 0.2273 - val_accuracy: 0.9121 - val_f1_score: 0.7536\n",
      "Epoch 9/20\n",
      "329/329 [==============================] - 47s 141ms/step - loss: 0.2064 - accuracy: 0.9203 - f1_score: 0.7612 - val_loss: 0.2281 - val_accuracy: 0.9098 - val_f1_score: 0.7511\n",
      "Epoch 10/20\n",
      "329/329 [==============================] - 49s 150ms/step - loss: 0.2062 - accuracy: 0.9200 - f1_score: 0.7594 - val_loss: 0.2243 - val_accuracy: 0.9094 - val_f1_score: 0.7339\n",
      "Epoch 11/20\n",
      "329/329 [==============================] - 37s 114ms/step - loss: 0.2071 - accuracy: 0.9196 - f1_score: 0.7573 - val_loss: 0.2278 - val_accuracy: 0.9119 - val_f1_score: 0.7650\n",
      "Epoch 12/20\n",
      "329/329 [==============================] - 42s 127ms/step - loss: 0.2062 - accuracy: 0.9202 - f1_score: 0.7602 - val_loss: 0.2315 - val_accuracy: 0.9107 - val_f1_score: 0.7538\n",
      "Epoch 13/20\n",
      "329/329 [==============================] - 36s 109ms/step - loss: 0.2054 - accuracy: 0.9201 - f1_score: 0.7571 - val_loss: 0.2291 - val_accuracy: 0.9082 - val_f1_score: 0.7312\n",
      "Epoch 14/20\n",
      "329/329 [==============================] - 46s 139ms/step - loss: 0.2046 - accuracy: 0.9204 - f1_score: 0.7596 - val_loss: 0.2302 - val_accuracy: 0.9082 - val_f1_score: 0.7411\n",
      "Epoch 15/20\n",
      "329/329 [==============================] - 30s 91ms/step - loss: 0.2047 - accuracy: 0.9204 - f1_score: 0.7588 - val_loss: 0.2292 - val_accuracy: 0.9072 - val_f1_score: 0.7292\n",
      "Epoch 16/20\n",
      "329/329 [==============================] - 40s 122ms/step - loss: 0.2042 - accuracy: 0.9206 - f1_score: 0.7604 - val_loss: 0.2341 - val_accuracy: 0.9083 - val_f1_score: 0.7370\n",
      "Epoch 17/20\n",
      "329/329 [==============================] - 42s 128ms/step - loss: 0.2043 - accuracy: 0.9207 - f1_score: 0.7609 - val_loss: 0.2325 - val_accuracy: 0.9075 - val_f1_score: 0.7423\n",
      "Epoch 18/20\n",
      "329/329 [==============================] - 47s 144ms/step - loss: 0.2050 - accuracy: 0.9201 - f1_score: 0.7605 - val_loss: 0.2317 - val_accuracy: 0.9097 - val_f1_score: 0.7520\n",
      "Epoch 19/20\n",
      "329/329 [==============================] - 48s 146ms/step - loss: 0.2054 - accuracy: 0.9192 - f1_score: 0.7602 - val_loss: 0.2274 - val_accuracy: 0.9090 - val_f1_score: 0.7507\n",
      "Epoch 20/20\n",
      "329/329 [==============================] - 55s 167ms/step - loss: 0.2042 - accuracy: 0.9201 - f1_score: 0.7605 - val_loss: 0.2281 - val_accuracy: 0.9077 - val_f1_score: 0.7415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fbb71191f30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_pos_train, x_train], y_train, epochs=20, batch_size=512, validation_data=([x_pos_val, x_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop([\"time\", \"label\"], axis=1).to_numpy()\n",
    "y_train = df_train[\"label\"].to_numpy().reshape(-1, 1)\n",
    "x_val = df_val.drop([\"time\", \"label\"], axis=1).to_numpy()\n",
    "y_val = df_val[\"label\"].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add anoother column whith 1 - label\n",
    "y_train = np.concatenate((y_train, 1 - y_train), axis=1)\n",
    "y_val = np.concatenate((y_val, 1 - y_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(block_size + 2, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy', tf.keras.metrics.F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "329/329 [==============================] - 8s 15ms/step - loss: 0.3426 - accuracy: 0.8831 - f1_score: 0.4774 - val_loss: 0.3770 - val_accuracy: 0.8818 - val_f1_score: 0.5216\n",
      "Epoch 2/20\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.3119 - accuracy: 0.8890 - f1_score: 0.5290 - val_loss: 0.3743 - val_accuracy: 0.8758 - val_f1_score: 0.6166\n",
      "Epoch 3/20\n",
      "329/329 [==============================] - 7s 20ms/step - loss: 0.3018 - accuracy: 0.8888 - f1_score: 0.5397 - val_loss: 0.3619 - val_accuracy: 0.8818 - val_f1_score: 0.5250\n",
      "Epoch 4/20\n",
      "329/329 [==============================] - 6s 18ms/step - loss: 0.2908 - accuracy: 0.8884 - f1_score: 0.5392 - val_loss: 0.3877 - val_accuracy: 0.8831 - val_f1_score: 0.5229\n",
      "Epoch 5/20\n",
      "329/329 [==============================] - 6s 19ms/step - loss: 0.2858 - accuracy: 0.8893 - f1_score: 0.5442 - val_loss: 0.4033 - val_accuracy: 0.8830 - val_f1_score: 0.5252\n",
      "Epoch 6/20\n",
      "329/329 [==============================] - 6s 18ms/step - loss: 0.2789 - accuracy: 0.8913 - f1_score: 0.5526 - val_loss: 0.4108 - val_accuracy: 0.8846 - val_f1_score: 0.5601\n",
      "Epoch 7/20\n",
      "329/329 [==============================] - 6s 17ms/step - loss: 0.2739 - accuracy: 0.8935 - f1_score: 0.5830 - val_loss: 0.4343 - val_accuracy: 0.8846 - val_f1_score: 0.5478\n",
      "Epoch 8/20\n",
      "329/329 [==============================] - 6s 17ms/step - loss: 0.2693 - accuracy: 0.8957 - f1_score: 0.6190 - val_loss: 0.3921 - val_accuracy: 0.8856 - val_f1_score: 0.5568\n",
      "Epoch 9/20\n",
      "329/329 [==============================] - 6s 18ms/step - loss: 0.2642 - accuracy: 0.8984 - f1_score: 0.6448 - val_loss: 0.3753 - val_accuracy: 0.8923 - val_f1_score: 0.6290\n",
      "Epoch 10/20\n",
      "329/329 [==============================] - 6s 19ms/step - loss: 0.2596 - accuracy: 0.9003 - f1_score: 0.6637 - val_loss: 0.3902 - val_accuracy: 0.8957 - val_f1_score: 0.6707\n",
      "Epoch 11/20\n",
      "329/329 [==============================] - 6s 18ms/step - loss: 0.2572 - accuracy: 0.9011 - f1_score: 0.6705 - val_loss: 0.4059 - val_accuracy: 0.8903 - val_f1_score: 0.6002\n",
      "Epoch 12/20\n",
      "329/329 [==============================] - 6s 17ms/step - loss: 0.2538 - accuracy: 0.9033 - f1_score: 0.6821 - val_loss: 0.3819 - val_accuracy: 0.8953 - val_f1_score: 0.6657\n",
      "Epoch 13/20\n",
      "329/329 [==============================] - 6s 17ms/step - loss: 0.2512 - accuracy: 0.9045 - f1_score: 0.6901 - val_loss: 0.3975 - val_accuracy: 0.8932 - val_f1_score: 0.6784\n",
      "Epoch 14/20\n",
      "329/329 [==============================] - 6s 17ms/step - loss: 0.2523 - accuracy: 0.9039 - f1_score: 0.6889 - val_loss: 0.3974 - val_accuracy: 0.8904 - val_f1_score: 0.6677\n",
      "Epoch 15/20\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.2505 - accuracy: 0.9040 - f1_score: 0.6903 - val_loss: 0.3823 - val_accuracy: 0.8983 - val_f1_score: 0.6823\n",
      "Epoch 16/20\n",
      "329/329 [==============================] - 5s 16ms/step - loss: 0.2473 - accuracy: 0.9055 - f1_score: 0.6969 - val_loss: 0.3973 - val_accuracy: 0.8981 - val_f1_score: 0.6902\n",
      "Epoch 17/20\n",
      "329/329 [==============================] - 5s 16ms/step - loss: 0.2447 - accuracy: 0.9063 - f1_score: 0.7021 - val_loss: 0.3995 - val_accuracy: 0.8997 - val_f1_score: 0.6834\n",
      "Epoch 18/20\n",
      "329/329 [==============================] - 5s 16ms/step - loss: 0.2447 - accuracy: 0.9067 - f1_score: 0.7025 - val_loss: 0.3895 - val_accuracy: 0.9029 - val_f1_score: 0.7095\n",
      "Epoch 19/20\n",
      "329/329 [==============================] - 5s 16ms/step - loss: 0.2442 - accuracy: 0.9067 - f1_score: 0.7042 - val_loss: 0.3852 - val_accuracy: 0.8976 - val_f1_score: 0.6987\n",
      "Epoch 20/20\n",
      "329/329 [==============================] - 6s 17ms/step - loss: 0.2420 - accuracy: 0.9078 - f1_score: 0.7100 - val_loss: 0.4012 - val_accuracy: 0.8984 - val_f1_score: 0.6819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fbb707f4250>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop([\"time\", \"label\"], axis=1).to_numpy()\n",
    "y_train = df_train[\"label\"].to_numpy().reshape(-1, 1)\n",
    "x_val = df_val.drop([\"time\", \"label\"], axis=1).to_numpy()\n",
    "y_val = df_val[\"label\"].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=1000, max_depth=10, learning_rate=0.01, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.68621\n",
      "[1]\tvalidation_0-logloss:0.67941\n",
      "[2]\tvalidation_0-logloss:0.67275\n",
      "[3]\tvalidation_0-logloss:0.66620\n",
      "[4]\tvalidation_0-logloss:0.65977\n",
      "[5]\tvalidation_0-logloss:0.65347\n",
      "[6]\tvalidation_0-logloss:0.64731\n",
      "[7]\tvalidation_0-logloss:0.64124\n",
      "[8]\tvalidation_0-logloss:0.63528\n",
      "[9]\tvalidation_0-logloss:0.62942\n",
      "[10]\tvalidation_0-logloss:0.62366\n",
      "[11]\tvalidation_0-logloss:0.61802\n",
      "[12]\tvalidation_0-logloss:0.61247\n",
      "[13]\tvalidation_0-logloss:0.60702\n",
      "[14]\tvalidation_0-logloss:0.60168\n",
      "[15]\tvalidation_0-logloss:0.59642\n",
      "[16]\tvalidation_0-logloss:0.59126\n",
      "[17]\tvalidation_0-logloss:0.58617\n",
      "[18]\tvalidation_0-logloss:0.58118\n",
      "[19]\tvalidation_0-logloss:0.57629\n",
      "[20]\tvalidation_0-logloss:0.57147\n",
      "[21]\tvalidation_0-logloss:0.56674\n",
      "[22]\tvalidation_0-logloss:0.56211\n",
      "[23]\tvalidation_0-logloss:0.55753\n",
      "[24]\tvalidation_0-logloss:0.55303\n",
      "[25]\tvalidation_0-logloss:0.54859\n",
      "[26]\tvalidation_0-logloss:0.54425\n",
      "[27]\tvalidation_0-logloss:0.53996\n",
      "[28]\tvalidation_0-logloss:0.53574\n",
      "[29]\tvalidation_0-logloss:0.53160\n",
      "[30]\tvalidation_0-logloss:0.52753\n",
      "[31]\tvalidation_0-logloss:0.52351\n",
      "[32]\tvalidation_0-logloss:0.51955\n",
      "[33]\tvalidation_0-logloss:0.51568\n",
      "[34]\tvalidation_0-logloss:0.51186\n",
      "[35]\tvalidation_0-logloss:0.50808\n",
      "[36]\tvalidation_0-logloss:0.50440\n",
      "[37]\tvalidation_0-logloss:0.50074\n",
      "[38]\tvalidation_0-logloss:0.49714\n",
      "[39]\tvalidation_0-logloss:0.49360\n",
      "[40]\tvalidation_0-logloss:0.49013\n",
      "[41]\tvalidation_0-logloss:0.48670\n",
      "[42]\tvalidation_0-logloss:0.48331\n",
      "[43]\tvalidation_0-logloss:0.47997\n",
      "[44]\tvalidation_0-logloss:0.47670\n",
      "[45]\tvalidation_0-logloss:0.47347\n",
      "[46]\tvalidation_0-logloss:0.47028\n",
      "[47]\tvalidation_0-logloss:0.46716\n",
      "[48]\tvalidation_0-logloss:0.46407\n",
      "[49]\tvalidation_0-logloss:0.46105\n",
      "[50]\tvalidation_0-logloss:0.45803\n",
      "[51]\tvalidation_0-logloss:0.45509\n",
      "[52]\tvalidation_0-logloss:0.45218\n",
      "[53]\tvalidation_0-logloss:0.44932\n",
      "[54]\tvalidation_0-logloss:0.44649\n",
      "[55]\tvalidation_0-logloss:0.44371\n",
      "[56]\tvalidation_0-logloss:0.44097\n",
      "[57]\tvalidation_0-logloss:0.43827\n",
      "[58]\tvalidation_0-logloss:0.43559\n",
      "[59]\tvalidation_0-logloss:0.43294\n",
      "[60]\tvalidation_0-logloss:0.43035\n",
      "[61]\tvalidation_0-logloss:0.42782\n",
      "[62]\tvalidation_0-logloss:0.42529\n",
      "[63]\tvalidation_0-logloss:0.42281\n",
      "[64]\tvalidation_0-logloss:0.42036\n",
      "[65]\tvalidation_0-logloss:0.41793\n",
      "[66]\tvalidation_0-logloss:0.41555\n",
      "[67]\tvalidation_0-logloss:0.41320\n",
      "[68]\tvalidation_0-logloss:0.41089\n",
      "[69]\tvalidation_0-logloss:0.40859\n",
      "[70]\tvalidation_0-logloss:0.40633\n",
      "[71]\tvalidation_0-logloss:0.40410\n",
      "[72]\tvalidation_0-logloss:0.40192\n",
      "[73]\tvalidation_0-logloss:0.39976\n",
      "[74]\tvalidation_0-logloss:0.39763\n",
      "[75]\tvalidation_0-logloss:0.39554\n",
      "[76]\tvalidation_0-logloss:0.39343\n",
      "[77]\tvalidation_0-logloss:0.39139\n",
      "[78]\tvalidation_0-logloss:0.38938\n",
      "[79]\tvalidation_0-logloss:0.38739\n",
      "[80]\tvalidation_0-logloss:0.38542\n",
      "[81]\tvalidation_0-logloss:0.38348\n",
      "[82]\tvalidation_0-logloss:0.38154\n",
      "[83]\tvalidation_0-logloss:0.37964\n",
      "[84]\tvalidation_0-logloss:0.37779\n",
      "[85]\tvalidation_0-logloss:0.37593\n",
      "[86]\tvalidation_0-logloss:0.37411\n",
      "[87]\tvalidation_0-logloss:0.37233\n",
      "[88]\tvalidation_0-logloss:0.37056\n",
      "[89]\tvalidation_0-logloss:0.36882\n",
      "[90]\tvalidation_0-logloss:0.36707\n",
      "[91]\tvalidation_0-logloss:0.36536\n",
      "[92]\tvalidation_0-logloss:0.36369\n",
      "[93]\tvalidation_0-logloss:0.36202\n",
      "[94]\tvalidation_0-logloss:0.36039\n",
      "[95]\tvalidation_0-logloss:0.35879\n",
      "[96]\tvalidation_0-logloss:0.35721\n",
      "[97]\tvalidation_0-logloss:0.35563\n",
      "[98]\tvalidation_0-logloss:0.35409\n",
      "[99]\tvalidation_0-logloss:0.35256\n",
      "[100]\tvalidation_0-logloss:0.35103\n",
      "[101]\tvalidation_0-logloss:0.34955\n",
      "[102]\tvalidation_0-logloss:0.34809\n",
      "[103]\tvalidation_0-logloss:0.34665\n",
      "[104]\tvalidation_0-logloss:0.34522\n",
      "[105]\tvalidation_0-logloss:0.34382\n",
      "[106]\tvalidation_0-logloss:0.34241\n",
      "[107]\tvalidation_0-logloss:0.34102\n",
      "[108]\tvalidation_0-logloss:0.33964\n",
      "[109]\tvalidation_0-logloss:0.33832\n",
      "[110]\tvalidation_0-logloss:0.33697\n",
      "[111]\tvalidation_0-logloss:0.33564\n",
      "[112]\tvalidation_0-logloss:0.33435\n",
      "[113]\tvalidation_0-logloss:0.33305\n",
      "[114]\tvalidation_0-logloss:0.33178\n",
      "[115]\tvalidation_0-logloss:0.33054\n",
      "[116]\tvalidation_0-logloss:0.32933\n",
      "[117]\tvalidation_0-logloss:0.32811\n",
      "[118]\tvalidation_0-logloss:0.32692\n",
      "[119]\tvalidation_0-logloss:0.32572\n",
      "[120]\tvalidation_0-logloss:0.32456\n",
      "[121]\tvalidation_0-logloss:0.32340\n",
      "[122]\tvalidation_0-logloss:0.32225\n",
      "[123]\tvalidation_0-logloss:0.32112\n",
      "[124]\tvalidation_0-logloss:0.32001\n",
      "[125]\tvalidation_0-logloss:0.31891\n",
      "[126]\tvalidation_0-logloss:0.31781\n",
      "[127]\tvalidation_0-logloss:0.31673\n",
      "[128]\tvalidation_0-logloss:0.31567\n",
      "[129]\tvalidation_0-logloss:0.31462\n",
      "[130]\tvalidation_0-logloss:0.31356\n",
      "[131]\tvalidation_0-logloss:0.31256\n",
      "[132]\tvalidation_0-logloss:0.31153\n",
      "[133]\tvalidation_0-logloss:0.31053\n",
      "[134]\tvalidation_0-logloss:0.30954\n",
      "[135]\tvalidation_0-logloss:0.30854\n",
      "[136]\tvalidation_0-logloss:0.30757\n",
      "[137]\tvalidation_0-logloss:0.30662\n",
      "[138]\tvalidation_0-logloss:0.30569\n",
      "[139]\tvalidation_0-logloss:0.30475\n",
      "[140]\tvalidation_0-logloss:0.30383\n",
      "[141]\tvalidation_0-logloss:0.30290\n",
      "[142]\tvalidation_0-logloss:0.30203\n",
      "[143]\tvalidation_0-logloss:0.30112\n",
      "[144]\tvalidation_0-logloss:0.30024\n",
      "[145]\tvalidation_0-logloss:0.29940\n",
      "[146]\tvalidation_0-logloss:0.29855\n",
      "[147]\tvalidation_0-logloss:0.29770\n",
      "[148]\tvalidation_0-logloss:0.29685\n",
      "[149]\tvalidation_0-logloss:0.29602\n",
      "[150]\tvalidation_0-logloss:0.29523\n",
      "[151]\tvalidation_0-logloss:0.29442\n",
      "[152]\tvalidation_0-logloss:0.29362\n",
      "[153]\tvalidation_0-logloss:0.29282\n",
      "[154]\tvalidation_0-logloss:0.29204\n",
      "[155]\tvalidation_0-logloss:0.29126\n",
      "[156]\tvalidation_0-logloss:0.29051\n",
      "[157]\tvalidation_0-logloss:0.28975\n",
      "[158]\tvalidation_0-logloss:0.28901\n",
      "[159]\tvalidation_0-logloss:0.28830\n",
      "[160]\tvalidation_0-logloss:0.28757\n",
      "[161]\tvalidation_0-logloss:0.28687\n",
      "[162]\tvalidation_0-logloss:0.28615\n",
      "[163]\tvalidation_0-logloss:0.28545\n",
      "[164]\tvalidation_0-logloss:0.28479\n",
      "[165]\tvalidation_0-logloss:0.28410\n",
      "[166]\tvalidation_0-logloss:0.28344\n",
      "[167]\tvalidation_0-logloss:0.28278\n",
      "[168]\tvalidation_0-logloss:0.28213\n",
      "[169]\tvalidation_0-logloss:0.28149\n",
      "[170]\tvalidation_0-logloss:0.28088\n",
      "[171]\tvalidation_0-logloss:0.28025\n",
      "[172]\tvalidation_0-logloss:0.27962\n",
      "[173]\tvalidation_0-logloss:0.27901\n",
      "[174]\tvalidation_0-logloss:0.27839\n",
      "[175]\tvalidation_0-logloss:0.27778\n",
      "[176]\tvalidation_0-logloss:0.27719\n",
      "[177]\tvalidation_0-logloss:0.27662\n",
      "[178]\tvalidation_0-logloss:0.27604\n",
      "[179]\tvalidation_0-logloss:0.27545\n",
      "[180]\tvalidation_0-logloss:0.27489\n",
      "[181]\tvalidation_0-logloss:0.27432\n",
      "[182]\tvalidation_0-logloss:0.27377\n",
      "[183]\tvalidation_0-logloss:0.27323\n",
      "[184]\tvalidation_0-logloss:0.27269\n",
      "[185]\tvalidation_0-logloss:0.27217\n",
      "[186]\tvalidation_0-logloss:0.27164\n",
      "[187]\tvalidation_0-logloss:0.27112\n",
      "[188]\tvalidation_0-logloss:0.27060\n",
      "[189]\tvalidation_0-logloss:0.27010\n",
      "[190]\tvalidation_0-logloss:0.26960\n",
      "[191]\tvalidation_0-logloss:0.26913\n",
      "[192]\tvalidation_0-logloss:0.26864\n",
      "[193]\tvalidation_0-logloss:0.26816\n",
      "[194]\tvalidation_0-logloss:0.26769\n",
      "[195]\tvalidation_0-logloss:0.26725\n",
      "[196]\tvalidation_0-logloss:0.26678\n",
      "[197]\tvalidation_0-logloss:0.26632\n",
      "[198]\tvalidation_0-logloss:0.26590\n",
      "[199]\tvalidation_0-logloss:0.26545\n",
      "[200]\tvalidation_0-logloss:0.26503\n",
      "[201]\tvalidation_0-logloss:0.26459\n",
      "[202]\tvalidation_0-logloss:0.26415\n",
      "[203]\tvalidation_0-logloss:0.26374\n",
      "[204]\tvalidation_0-logloss:0.26333\n",
      "[205]\tvalidation_0-logloss:0.26290\n",
      "[206]\tvalidation_0-logloss:0.26247\n",
      "[207]\tvalidation_0-logloss:0.26206\n",
      "[208]\tvalidation_0-logloss:0.26168\n",
      "[209]\tvalidation_0-logloss:0.26129\n",
      "[210]\tvalidation_0-logloss:0.26089\n",
      "[211]\tvalidation_0-logloss:0.26050\n",
      "[212]\tvalidation_0-logloss:0.26013\n",
      "[213]\tvalidation_0-logloss:0.25976\n",
      "[214]\tvalidation_0-logloss:0.25938\n",
      "[215]\tvalidation_0-logloss:0.25902\n",
      "[216]\tvalidation_0-logloss:0.25866\n",
      "[217]\tvalidation_0-logloss:0.25829\n",
      "[218]\tvalidation_0-logloss:0.25794\n",
      "[219]\tvalidation_0-logloss:0.25760\n",
      "[220]\tvalidation_0-logloss:0.25726\n",
      "[221]\tvalidation_0-logloss:0.25692\n",
      "[222]\tvalidation_0-logloss:0.25658\n",
      "[223]\tvalidation_0-logloss:0.25625\n",
      "[224]\tvalidation_0-logloss:0.25592\n",
      "[225]\tvalidation_0-logloss:0.25559\n",
      "[226]\tvalidation_0-logloss:0.25526\n",
      "[227]\tvalidation_0-logloss:0.25496\n",
      "[228]\tvalidation_0-logloss:0.25464\n",
      "[229]\tvalidation_0-logloss:0.25433\n",
      "[230]\tvalidation_0-logloss:0.25402\n",
      "[231]\tvalidation_0-logloss:0.25372\n",
      "[232]\tvalidation_0-logloss:0.25342\n",
      "[233]\tvalidation_0-logloss:0.25311\n",
      "[234]\tvalidation_0-logloss:0.25282\n",
      "[235]\tvalidation_0-logloss:0.25254\n",
      "[236]\tvalidation_0-logloss:0.25224\n",
      "[237]\tvalidation_0-logloss:0.25196\n",
      "[238]\tvalidation_0-logloss:0.25167\n",
      "[239]\tvalidation_0-logloss:0.25138\n",
      "[240]\tvalidation_0-logloss:0.25110\n",
      "[241]\tvalidation_0-logloss:0.25082\n",
      "[242]\tvalidation_0-logloss:0.25056\n",
      "[243]\tvalidation_0-logloss:0.25030\n",
      "[244]\tvalidation_0-logloss:0.25004\n",
      "[245]\tvalidation_0-logloss:0.24978\n",
      "[246]\tvalidation_0-logloss:0.24952\n",
      "[247]\tvalidation_0-logloss:0.24925\n",
      "[248]\tvalidation_0-logloss:0.24901\n",
      "[249]\tvalidation_0-logloss:0.24875\n",
      "[250]\tvalidation_0-logloss:0.24851\n",
      "[251]\tvalidation_0-logloss:0.24825\n",
      "[252]\tvalidation_0-logloss:0.24801\n",
      "[253]\tvalidation_0-logloss:0.24777\n",
      "[254]\tvalidation_0-logloss:0.24753\n",
      "[255]\tvalidation_0-logloss:0.24730\n",
      "[256]\tvalidation_0-logloss:0.24707\n",
      "[257]\tvalidation_0-logloss:0.24683\n",
      "[258]\tvalidation_0-logloss:0.24661\n",
      "[259]\tvalidation_0-logloss:0.24639\n",
      "[260]\tvalidation_0-logloss:0.24616\n",
      "[261]\tvalidation_0-logloss:0.24594\n",
      "[262]\tvalidation_0-logloss:0.24574\n",
      "[263]\tvalidation_0-logloss:0.24553\n",
      "[264]\tvalidation_0-logloss:0.24532\n",
      "[265]\tvalidation_0-logloss:0.24512\n",
      "[266]\tvalidation_0-logloss:0.24491\n",
      "[267]\tvalidation_0-logloss:0.24472\n",
      "[268]\tvalidation_0-logloss:0.24453\n",
      "[269]\tvalidation_0-logloss:0.24433\n",
      "[270]\tvalidation_0-logloss:0.24415\n",
      "[271]\tvalidation_0-logloss:0.24396\n",
      "[272]\tvalidation_0-logloss:0.24378\n",
      "[273]\tvalidation_0-logloss:0.24359\n",
      "[274]\tvalidation_0-logloss:0.24340\n",
      "[275]\tvalidation_0-logloss:0.24323\n",
      "[276]\tvalidation_0-logloss:0.24306\n",
      "[277]\tvalidation_0-logloss:0.24289\n",
      "[278]\tvalidation_0-logloss:0.24272\n",
      "[279]\tvalidation_0-logloss:0.24256\n",
      "[280]\tvalidation_0-logloss:0.24239\n",
      "[281]\tvalidation_0-logloss:0.24223\n",
      "[282]\tvalidation_0-logloss:0.24207\n",
      "[283]\tvalidation_0-logloss:0.24192\n",
      "[284]\tvalidation_0-logloss:0.24176\n",
      "[285]\tvalidation_0-logloss:0.24160\n",
      "[286]\tvalidation_0-logloss:0.24143\n",
      "[287]\tvalidation_0-logloss:0.24127\n",
      "[288]\tvalidation_0-logloss:0.24112\n",
      "[289]\tvalidation_0-logloss:0.24097\n",
      "[290]\tvalidation_0-logloss:0.24082\n",
      "[291]\tvalidation_0-logloss:0.24067\n",
      "[292]\tvalidation_0-logloss:0.24052\n",
      "[293]\tvalidation_0-logloss:0.24038\n",
      "[294]\tvalidation_0-logloss:0.24025\n",
      "[295]\tvalidation_0-logloss:0.24010\n",
      "[296]\tvalidation_0-logloss:0.23995\n",
      "[297]\tvalidation_0-logloss:0.23982\n",
      "[298]\tvalidation_0-logloss:0.23969\n",
      "[299]\tvalidation_0-logloss:0.23956\n",
      "[300]\tvalidation_0-logloss:0.23942\n",
      "[301]\tvalidation_0-logloss:0.23930\n",
      "[302]\tvalidation_0-logloss:0.23918\n",
      "[303]\tvalidation_0-logloss:0.23905\n",
      "[304]\tvalidation_0-logloss:0.23892\n",
      "[305]\tvalidation_0-logloss:0.23880\n",
      "[306]\tvalidation_0-logloss:0.23869\n",
      "[307]\tvalidation_0-logloss:0.23857\n",
      "[308]\tvalidation_0-logloss:0.23846\n",
      "[309]\tvalidation_0-logloss:0.23834\n",
      "[310]\tvalidation_0-logloss:0.23822\n",
      "[311]\tvalidation_0-logloss:0.23811\n",
      "[312]\tvalidation_0-logloss:0.23801\n",
      "[313]\tvalidation_0-logloss:0.23790\n",
      "[314]\tvalidation_0-logloss:0.23779\n",
      "[315]\tvalidation_0-logloss:0.23768\n",
      "[316]\tvalidation_0-logloss:0.23758\n",
      "[317]\tvalidation_0-logloss:0.23748\n",
      "[318]\tvalidation_0-logloss:0.23738\n",
      "[319]\tvalidation_0-logloss:0.23727\n",
      "[320]\tvalidation_0-logloss:0.23717\n",
      "[321]\tvalidation_0-logloss:0.23707\n",
      "[322]\tvalidation_0-logloss:0.23697\n",
      "[323]\tvalidation_0-logloss:0.23686\n",
      "[324]\tvalidation_0-logloss:0.23676\n",
      "[325]\tvalidation_0-logloss:0.23666\n",
      "[326]\tvalidation_0-logloss:0.23657\n",
      "[327]\tvalidation_0-logloss:0.23647\n",
      "[328]\tvalidation_0-logloss:0.23638\n",
      "[329]\tvalidation_0-logloss:0.23628\n",
      "[330]\tvalidation_0-logloss:0.23619\n",
      "[331]\tvalidation_0-logloss:0.23609\n",
      "[332]\tvalidation_0-logloss:0.23601\n",
      "[333]\tvalidation_0-logloss:0.23592\n",
      "[334]\tvalidation_0-logloss:0.23584\n",
      "[335]\tvalidation_0-logloss:0.23575\n",
      "[336]\tvalidation_0-logloss:0.23567\n",
      "[337]\tvalidation_0-logloss:0.23559\n",
      "[338]\tvalidation_0-logloss:0.23551\n",
      "[339]\tvalidation_0-logloss:0.23542\n",
      "[340]\tvalidation_0-logloss:0.23533\n",
      "[341]\tvalidation_0-logloss:0.23525\n",
      "[342]\tvalidation_0-logloss:0.23517\n",
      "[343]\tvalidation_0-logloss:0.23509\n",
      "[344]\tvalidation_0-logloss:0.23501\n",
      "[345]\tvalidation_0-logloss:0.23492\n",
      "[346]\tvalidation_0-logloss:0.23483\n",
      "[347]\tvalidation_0-logloss:0.23477\n",
      "[348]\tvalidation_0-logloss:0.23469\n",
      "[349]\tvalidation_0-logloss:0.23462\n",
      "[350]\tvalidation_0-logloss:0.23454\n",
      "[351]\tvalidation_0-logloss:0.23447\n",
      "[352]\tvalidation_0-logloss:0.23439\n",
      "[353]\tvalidation_0-logloss:0.23432\n",
      "[354]\tvalidation_0-logloss:0.23425\n",
      "[355]\tvalidation_0-logloss:0.23418\n",
      "[356]\tvalidation_0-logloss:0.23411\n",
      "[357]\tvalidation_0-logloss:0.23404\n",
      "[358]\tvalidation_0-logloss:0.23397\n",
      "[359]\tvalidation_0-logloss:0.23390\n",
      "[360]\tvalidation_0-logloss:0.23383\n",
      "[361]\tvalidation_0-logloss:0.23376\n",
      "[362]\tvalidation_0-logloss:0.23371\n",
      "[363]\tvalidation_0-logloss:0.23364\n",
      "[364]\tvalidation_0-logloss:0.23358\n",
      "[365]\tvalidation_0-logloss:0.23352\n",
      "[366]\tvalidation_0-logloss:0.23345\n",
      "[367]\tvalidation_0-logloss:0.23339\n",
      "[368]\tvalidation_0-logloss:0.23332\n",
      "[369]\tvalidation_0-logloss:0.23326\n",
      "[370]\tvalidation_0-logloss:0.23320\n",
      "[371]\tvalidation_0-logloss:0.23314\n",
      "[372]\tvalidation_0-logloss:0.23308\n",
      "[373]\tvalidation_0-logloss:0.23302\n",
      "[374]\tvalidation_0-logloss:0.23297\n",
      "[375]\tvalidation_0-logloss:0.23291\n",
      "[376]\tvalidation_0-logloss:0.23285\n",
      "[377]\tvalidation_0-logloss:0.23279\n",
      "[378]\tvalidation_0-logloss:0.23273\n",
      "[379]\tvalidation_0-logloss:0.23268\n",
      "[380]\tvalidation_0-logloss:0.23263\n",
      "[381]\tvalidation_0-logloss:0.23257\n",
      "[382]\tvalidation_0-logloss:0.23253\n",
      "[383]\tvalidation_0-logloss:0.23247\n",
      "[384]\tvalidation_0-logloss:0.23242\n",
      "[385]\tvalidation_0-logloss:0.23237\n",
      "[386]\tvalidation_0-logloss:0.23233\n",
      "[387]\tvalidation_0-logloss:0.23228\n",
      "[388]\tvalidation_0-logloss:0.23223\n",
      "[389]\tvalidation_0-logloss:0.23218\n",
      "[390]\tvalidation_0-logloss:0.23214\n",
      "[391]\tvalidation_0-logloss:0.23209\n",
      "[392]\tvalidation_0-logloss:0.23204\n",
      "[393]\tvalidation_0-logloss:0.23199\n",
      "[394]\tvalidation_0-logloss:0.23195\n",
      "[395]\tvalidation_0-logloss:0.23189\n",
      "[396]\tvalidation_0-logloss:0.23185\n",
      "[397]\tvalidation_0-logloss:0.23181\n",
      "[398]\tvalidation_0-logloss:0.23177\n",
      "[399]\tvalidation_0-logloss:0.23173\n",
      "[400]\tvalidation_0-logloss:0.23167\n",
      "[401]\tvalidation_0-logloss:0.23163\n",
      "[402]\tvalidation_0-logloss:0.23159\n",
      "[403]\tvalidation_0-logloss:0.23156\n",
      "[404]\tvalidation_0-logloss:0.23151\n",
      "[405]\tvalidation_0-logloss:0.23148\n",
      "[406]\tvalidation_0-logloss:0.23144\n",
      "[407]\tvalidation_0-logloss:0.23140\n",
      "[408]\tvalidation_0-logloss:0.23135\n",
      "[409]\tvalidation_0-logloss:0.23131\n",
      "[410]\tvalidation_0-logloss:0.23128\n",
      "[411]\tvalidation_0-logloss:0.23124\n",
      "[412]\tvalidation_0-logloss:0.23121\n",
      "[413]\tvalidation_0-logloss:0.23118\n",
      "[414]\tvalidation_0-logloss:0.23114\n",
      "[415]\tvalidation_0-logloss:0.23110\n",
      "[416]\tvalidation_0-logloss:0.23107\n",
      "[417]\tvalidation_0-logloss:0.23103\n",
      "[418]\tvalidation_0-logloss:0.23101\n",
      "[419]\tvalidation_0-logloss:0.23098\n",
      "[420]\tvalidation_0-logloss:0.23096\n",
      "[421]\tvalidation_0-logloss:0.23093\n",
      "[422]\tvalidation_0-logloss:0.23089\n",
      "[423]\tvalidation_0-logloss:0.23087\n",
      "[424]\tvalidation_0-logloss:0.23083\n",
      "[425]\tvalidation_0-logloss:0.23079\n",
      "[426]\tvalidation_0-logloss:0.23076\n",
      "[427]\tvalidation_0-logloss:0.23073\n",
      "[428]\tvalidation_0-logloss:0.23070\n",
      "[429]\tvalidation_0-logloss:0.23068\n",
      "[430]\tvalidation_0-logloss:0.23064\n",
      "[431]\tvalidation_0-logloss:0.23061\n",
      "[432]\tvalidation_0-logloss:0.23058\n",
      "[433]\tvalidation_0-logloss:0.23055\n",
      "[434]\tvalidation_0-logloss:0.23051\n",
      "[435]\tvalidation_0-logloss:0.23048\n",
      "[436]\tvalidation_0-logloss:0.23045\n",
      "[437]\tvalidation_0-logloss:0.23041\n",
      "[438]\tvalidation_0-logloss:0.23039\n",
      "[439]\tvalidation_0-logloss:0.23035\n",
      "[440]\tvalidation_0-logloss:0.23032\n",
      "[441]\tvalidation_0-logloss:0.23030\n",
      "[442]\tvalidation_0-logloss:0.23027\n",
      "[443]\tvalidation_0-logloss:0.23025\n",
      "[444]\tvalidation_0-logloss:0.23022\n",
      "[445]\tvalidation_0-logloss:0.23020\n",
      "[446]\tvalidation_0-logloss:0.23018\n",
      "[447]\tvalidation_0-logloss:0.23016\n",
      "[448]\tvalidation_0-logloss:0.23013\n",
      "[449]\tvalidation_0-logloss:0.23011\n",
      "[450]\tvalidation_0-logloss:0.23009\n",
      "[451]\tvalidation_0-logloss:0.23006\n",
      "[452]\tvalidation_0-logloss:0.23005\n",
      "[453]\tvalidation_0-logloss:0.23003\n",
      "[454]\tvalidation_0-logloss:0.23001\n",
      "[455]\tvalidation_0-logloss:0.23000\n",
      "[456]\tvalidation_0-logloss:0.22999\n",
      "[457]\tvalidation_0-logloss:0.22996\n",
      "[458]\tvalidation_0-logloss:0.22994\n",
      "[459]\tvalidation_0-logloss:0.22992\n",
      "[460]\tvalidation_0-logloss:0.22990\n",
      "[461]\tvalidation_0-logloss:0.22988\n",
      "[462]\tvalidation_0-logloss:0.22986\n",
      "[463]\tvalidation_0-logloss:0.22983\n",
      "[464]\tvalidation_0-logloss:0.22981\n",
      "[465]\tvalidation_0-logloss:0.22980\n",
      "[466]\tvalidation_0-logloss:0.22978\n",
      "[467]\tvalidation_0-logloss:0.22977\n",
      "[468]\tvalidation_0-logloss:0.22975\n",
      "[469]\tvalidation_0-logloss:0.22974\n",
      "[470]\tvalidation_0-logloss:0.22972\n",
      "[471]\tvalidation_0-logloss:0.22971\n",
      "[472]\tvalidation_0-logloss:0.22969\n",
      "[473]\tvalidation_0-logloss:0.22968\n",
      "[474]\tvalidation_0-logloss:0.22966\n",
      "[475]\tvalidation_0-logloss:0.22964\n",
      "[476]\tvalidation_0-logloss:0.22962\n",
      "[477]\tvalidation_0-logloss:0.22961\n",
      "[478]\tvalidation_0-logloss:0.22958\n",
      "[479]\tvalidation_0-logloss:0.22957\n",
      "[480]\tvalidation_0-logloss:0.22955\n",
      "[481]\tvalidation_0-logloss:0.22953\n",
      "[482]\tvalidation_0-logloss:0.22953\n",
      "[483]\tvalidation_0-logloss:0.22951\n",
      "[484]\tvalidation_0-logloss:0.22949\n",
      "[485]\tvalidation_0-logloss:0.22948\n",
      "[486]\tvalidation_0-logloss:0.22946\n",
      "[487]\tvalidation_0-logloss:0.22944\n",
      "[488]\tvalidation_0-logloss:0.22942\n",
      "[489]\tvalidation_0-logloss:0.22940\n",
      "[490]\tvalidation_0-logloss:0.22939\n",
      "[491]\tvalidation_0-logloss:0.22937\n",
      "[492]\tvalidation_0-logloss:0.22935\n",
      "[493]\tvalidation_0-logloss:0.22933\n",
      "[494]\tvalidation_0-logloss:0.22931\n",
      "[495]\tvalidation_0-logloss:0.22930\n",
      "[496]\tvalidation_0-logloss:0.22928\n",
      "[497]\tvalidation_0-logloss:0.22927\n",
      "[498]\tvalidation_0-logloss:0.22925\n",
      "[499]\tvalidation_0-logloss:0.22922\n",
      "[500]\tvalidation_0-logloss:0.22920\n",
      "[501]\tvalidation_0-logloss:0.22918\n",
      "[502]\tvalidation_0-logloss:0.22916\n",
      "[503]\tvalidation_0-logloss:0.22915\n",
      "[504]\tvalidation_0-logloss:0.22913\n",
      "[505]\tvalidation_0-logloss:0.22912\n",
      "[506]\tvalidation_0-logloss:0.22910\n",
      "[507]\tvalidation_0-logloss:0.22908\n",
      "[508]\tvalidation_0-logloss:0.22907\n",
      "[509]\tvalidation_0-logloss:0.22906\n",
      "[510]\tvalidation_0-logloss:0.22905\n",
      "[511]\tvalidation_0-logloss:0.22904\n",
      "[512]\tvalidation_0-logloss:0.22902\n",
      "[513]\tvalidation_0-logloss:0.22901\n",
      "[514]\tvalidation_0-logloss:0.22900\n",
      "[515]\tvalidation_0-logloss:0.22898\n",
      "[516]\tvalidation_0-logloss:0.22897\n",
      "[517]\tvalidation_0-logloss:0.22895\n",
      "[518]\tvalidation_0-logloss:0.22894\n",
      "[519]\tvalidation_0-logloss:0.22892\n",
      "[520]\tvalidation_0-logloss:0.22891\n",
      "[521]\tvalidation_0-logloss:0.22890\n",
      "[522]\tvalidation_0-logloss:0.22888\n",
      "[523]\tvalidation_0-logloss:0.22887\n",
      "[524]\tvalidation_0-logloss:0.22886\n",
      "[525]\tvalidation_0-logloss:0.22884\n",
      "[526]\tvalidation_0-logloss:0.22883\n",
      "[527]\tvalidation_0-logloss:0.22881\n",
      "[528]\tvalidation_0-logloss:0.22880\n",
      "[529]\tvalidation_0-logloss:0.22878\n",
      "[530]\tvalidation_0-logloss:0.22877\n",
      "[531]\tvalidation_0-logloss:0.22876\n",
      "[532]\tvalidation_0-logloss:0.22874\n",
      "[533]\tvalidation_0-logloss:0.22873\n",
      "[534]\tvalidation_0-logloss:0.22871\n",
      "[535]\tvalidation_0-logloss:0.22870\n",
      "[536]\tvalidation_0-logloss:0.22868\n",
      "[537]\tvalidation_0-logloss:0.22867\n",
      "[538]\tvalidation_0-logloss:0.22866\n",
      "[539]\tvalidation_0-logloss:0.22865\n",
      "[540]\tvalidation_0-logloss:0.22865\n",
      "[541]\tvalidation_0-logloss:0.22863\n",
      "[542]\tvalidation_0-logloss:0.22862\n",
      "[543]\tvalidation_0-logloss:0.22861\n",
      "[544]\tvalidation_0-logloss:0.22859\n",
      "[545]\tvalidation_0-logloss:0.22858\n",
      "[546]\tvalidation_0-logloss:0.22857\n",
      "[547]\tvalidation_0-logloss:0.22856\n",
      "[548]\tvalidation_0-logloss:0.22855\n",
      "[549]\tvalidation_0-logloss:0.22854\n",
      "[550]\tvalidation_0-logloss:0.22853\n",
      "[551]\tvalidation_0-logloss:0.22853\n",
      "[552]\tvalidation_0-logloss:0.22851\n",
      "[553]\tvalidation_0-logloss:0.22850\n",
      "[554]\tvalidation_0-logloss:0.22849\n",
      "[555]\tvalidation_0-logloss:0.22849\n",
      "[556]\tvalidation_0-logloss:0.22847\n",
      "[557]\tvalidation_0-logloss:0.22847\n",
      "[558]\tvalidation_0-logloss:0.22846\n",
      "[559]\tvalidation_0-logloss:0.22845\n",
      "[560]\tvalidation_0-logloss:0.22844\n",
      "[561]\tvalidation_0-logloss:0.22843\n",
      "[562]\tvalidation_0-logloss:0.22842\n",
      "[563]\tvalidation_0-logloss:0.22842\n",
      "[564]\tvalidation_0-logloss:0.22841\n",
      "[565]\tvalidation_0-logloss:0.22841\n",
      "[566]\tvalidation_0-logloss:0.22840\n",
      "[567]\tvalidation_0-logloss:0.22839\n",
      "[568]\tvalidation_0-logloss:0.22838\n",
      "[569]\tvalidation_0-logloss:0.22837\n",
      "[570]\tvalidation_0-logloss:0.22836\n",
      "[571]\tvalidation_0-logloss:0.22835\n",
      "[572]\tvalidation_0-logloss:0.22834\n",
      "[573]\tvalidation_0-logloss:0.22834\n",
      "[574]\tvalidation_0-logloss:0.22833\n",
      "[575]\tvalidation_0-logloss:0.22832\n",
      "[576]\tvalidation_0-logloss:0.22831\n",
      "[577]\tvalidation_0-logloss:0.22831\n",
      "[578]\tvalidation_0-logloss:0.22830\n",
      "[579]\tvalidation_0-logloss:0.22830\n",
      "[580]\tvalidation_0-logloss:0.22829\n",
      "[581]\tvalidation_0-logloss:0.22828\n",
      "[582]\tvalidation_0-logloss:0.22827\n",
      "[583]\tvalidation_0-logloss:0.22827\n",
      "[584]\tvalidation_0-logloss:0.22826\n",
      "[585]\tvalidation_0-logloss:0.22826\n",
      "[586]\tvalidation_0-logloss:0.22826\n",
      "[587]\tvalidation_0-logloss:0.22825\n",
      "[588]\tvalidation_0-logloss:0.22826\n",
      "[589]\tvalidation_0-logloss:0.22825\n",
      "[590]\tvalidation_0-logloss:0.22824\n",
      "[591]\tvalidation_0-logloss:0.22823\n",
      "[592]\tvalidation_0-logloss:0.22823\n",
      "[593]\tvalidation_0-logloss:0.22823\n",
      "[594]\tvalidation_0-logloss:0.22822\n",
      "[595]\tvalidation_0-logloss:0.22822\n",
      "[596]\tvalidation_0-logloss:0.22821\n",
      "[597]\tvalidation_0-logloss:0.22821\n",
      "[598]\tvalidation_0-logloss:0.22821\n",
      "[599]\tvalidation_0-logloss:0.22820\n",
      "[600]\tvalidation_0-logloss:0.22820\n",
      "[601]\tvalidation_0-logloss:0.22819\n",
      "[602]\tvalidation_0-logloss:0.22819\n",
      "[603]\tvalidation_0-logloss:0.22818\n",
      "[604]\tvalidation_0-logloss:0.22818\n",
      "[605]\tvalidation_0-logloss:0.22817\n",
      "[606]\tvalidation_0-logloss:0.22817\n",
      "[607]\tvalidation_0-logloss:0.22816\n",
      "[608]\tvalidation_0-logloss:0.22815\n",
      "[609]\tvalidation_0-logloss:0.22815\n",
      "[610]\tvalidation_0-logloss:0.22815\n",
      "[611]\tvalidation_0-logloss:0.22815\n",
      "[612]\tvalidation_0-logloss:0.22814\n",
      "[613]\tvalidation_0-logloss:0.22813\n",
      "[614]\tvalidation_0-logloss:0.22814\n",
      "[615]\tvalidation_0-logloss:0.22813\n",
      "[616]\tvalidation_0-logloss:0.22812\n",
      "[617]\tvalidation_0-logloss:0.22812\n",
      "[618]\tvalidation_0-logloss:0.22812\n",
      "[619]\tvalidation_0-logloss:0.22811\n",
      "[620]\tvalidation_0-logloss:0.22810\n",
      "[621]\tvalidation_0-logloss:0.22810\n",
      "[622]\tvalidation_0-logloss:0.22810\n",
      "[623]\tvalidation_0-logloss:0.22809\n",
      "[624]\tvalidation_0-logloss:0.22809\n",
      "[625]\tvalidation_0-logloss:0.22809\n",
      "[626]\tvalidation_0-logloss:0.22809\n",
      "[627]\tvalidation_0-logloss:0.22808\n",
      "[628]\tvalidation_0-logloss:0.22808\n",
      "[629]\tvalidation_0-logloss:0.22807\n",
      "[630]\tvalidation_0-logloss:0.22807\n",
      "[631]\tvalidation_0-logloss:0.22807\n",
      "[632]\tvalidation_0-logloss:0.22807\n",
      "[633]\tvalidation_0-logloss:0.22807\n",
      "[634]\tvalidation_0-logloss:0.22808\n",
      "[635]\tvalidation_0-logloss:0.22807\n",
      "[636]\tvalidation_0-logloss:0.22808\n",
      "[637]\tvalidation_0-logloss:0.22807\n",
      "[638]\tvalidation_0-logloss:0.22807\n",
      "[639]\tvalidation_0-logloss:0.22807\n",
      "[640]\tvalidation_0-logloss:0.22806\n",
      "[641]\tvalidation_0-logloss:0.22806\n",
      "[642]\tvalidation_0-logloss:0.22806\n",
      "[643]\tvalidation_0-logloss:0.22805\n",
      "[644]\tvalidation_0-logloss:0.22805\n",
      "[645]\tvalidation_0-logloss:0.22804\n",
      "[646]\tvalidation_0-logloss:0.22804\n",
      "[647]\tvalidation_0-logloss:0.22804\n",
      "[648]\tvalidation_0-logloss:0.22804\n",
      "[649]\tvalidation_0-logloss:0.22804\n",
      "[650]\tvalidation_0-logloss:0.22803\n",
      "[651]\tvalidation_0-logloss:0.22803\n",
      "[652]\tvalidation_0-logloss:0.22803\n",
      "[653]\tvalidation_0-logloss:0.22803\n",
      "[654]\tvalidation_0-logloss:0.22802\n",
      "[655]\tvalidation_0-logloss:0.22803\n",
      "[656]\tvalidation_0-logloss:0.22802\n",
      "[657]\tvalidation_0-logloss:0.22803\n",
      "[658]\tvalidation_0-logloss:0.22802\n",
      "[659]\tvalidation_0-logloss:0.22802\n",
      "[660]\tvalidation_0-logloss:0.22802\n",
      "[661]\tvalidation_0-logloss:0.22802\n",
      "[662]\tvalidation_0-logloss:0.22802\n",
      "[663]\tvalidation_0-logloss:0.22801\n",
      "[664]\tvalidation_0-logloss:0.22802\n",
      "[665]\tvalidation_0-logloss:0.22802\n",
      "[666]\tvalidation_0-logloss:0.22801\n",
      "[667]\tvalidation_0-logloss:0.22800\n",
      "[668]\tvalidation_0-logloss:0.22800\n",
      "[669]\tvalidation_0-logloss:0.22800\n",
      "[670]\tvalidation_0-logloss:0.22800\n",
      "[671]\tvalidation_0-logloss:0.22800\n",
      "[672]\tvalidation_0-logloss:0.22800\n",
      "[673]\tvalidation_0-logloss:0.22800\n",
      "[674]\tvalidation_0-logloss:0.22800\n",
      "[675]\tvalidation_0-logloss:0.22800\n",
      "[676]\tvalidation_0-logloss:0.22799\n",
      "[677]\tvalidation_0-logloss:0.22799\n",
      "[678]\tvalidation_0-logloss:0.22799\n",
      "[679]\tvalidation_0-logloss:0.22799\n",
      "[680]\tvalidation_0-logloss:0.22798\n",
      "[681]\tvalidation_0-logloss:0.22798\n",
      "[682]\tvalidation_0-logloss:0.22798\n",
      "[683]\tvalidation_0-logloss:0.22798\n",
      "[684]\tvalidation_0-logloss:0.22797\n",
      "[685]\tvalidation_0-logloss:0.22797\n",
      "[686]\tvalidation_0-logloss:0.22797\n",
      "[687]\tvalidation_0-logloss:0.22797\n",
      "[688]\tvalidation_0-logloss:0.22796\n",
      "[689]\tvalidation_0-logloss:0.22796\n",
      "[690]\tvalidation_0-logloss:0.22796\n",
      "[691]\tvalidation_0-logloss:0.22796\n",
      "[692]\tvalidation_0-logloss:0.22796\n",
      "[693]\tvalidation_0-logloss:0.22796\n",
      "[694]\tvalidation_0-logloss:0.22795\n",
      "[695]\tvalidation_0-logloss:0.22795\n",
      "[696]\tvalidation_0-logloss:0.22795\n",
      "[697]\tvalidation_0-logloss:0.22795\n",
      "[698]\tvalidation_0-logloss:0.22795\n",
      "[699]\tvalidation_0-logloss:0.22795\n",
      "[700]\tvalidation_0-logloss:0.22795\n",
      "[701]\tvalidation_0-logloss:0.22795\n",
      "[702]\tvalidation_0-logloss:0.22795\n",
      "[703]\tvalidation_0-logloss:0.22794\n",
      "[704]\tvalidation_0-logloss:0.22794\n",
      "[705]\tvalidation_0-logloss:0.22794\n",
      "[706]\tvalidation_0-logloss:0.22794\n",
      "[707]\tvalidation_0-logloss:0.22794\n",
      "[708]\tvalidation_0-logloss:0.22794\n",
      "[709]\tvalidation_0-logloss:0.22793\n",
      "[710]\tvalidation_0-logloss:0.22793\n",
      "[711]\tvalidation_0-logloss:0.22793\n",
      "[712]\tvalidation_0-logloss:0.22793\n",
      "[713]\tvalidation_0-logloss:0.22792\n",
      "[714]\tvalidation_0-logloss:0.22792\n",
      "[715]\tvalidation_0-logloss:0.22792\n",
      "[716]\tvalidation_0-logloss:0.22791\n",
      "[717]\tvalidation_0-logloss:0.22791\n",
      "[718]\tvalidation_0-logloss:0.22791\n",
      "[719]\tvalidation_0-logloss:0.22791\n",
      "[720]\tvalidation_0-logloss:0.22791\n",
      "[721]\tvalidation_0-logloss:0.22790\n",
      "[722]\tvalidation_0-logloss:0.22789\n",
      "[723]\tvalidation_0-logloss:0.22790\n",
      "[724]\tvalidation_0-logloss:0.22790\n",
      "[725]\tvalidation_0-logloss:0.22789\n",
      "[726]\tvalidation_0-logloss:0.22789\n",
      "[727]\tvalidation_0-logloss:0.22789\n",
      "[728]\tvalidation_0-logloss:0.22788\n",
      "[729]\tvalidation_0-logloss:0.22788\n",
      "[730]\tvalidation_0-logloss:0.22788\n",
      "[731]\tvalidation_0-logloss:0.22788\n",
      "[732]\tvalidation_0-logloss:0.22788\n",
      "[733]\tvalidation_0-logloss:0.22788\n",
      "[734]\tvalidation_0-logloss:0.22788\n",
      "[735]\tvalidation_0-logloss:0.22787\n",
      "[736]\tvalidation_0-logloss:0.22787\n",
      "[737]\tvalidation_0-logloss:0.22787\n",
      "[738]\tvalidation_0-logloss:0.22787\n",
      "[739]\tvalidation_0-logloss:0.22787\n",
      "[740]\tvalidation_0-logloss:0.22787\n",
      "[741]\tvalidation_0-logloss:0.22787\n",
      "[742]\tvalidation_0-logloss:0.22787\n",
      "[743]\tvalidation_0-logloss:0.22786\n",
      "[744]\tvalidation_0-logloss:0.22786\n",
      "[745]\tvalidation_0-logloss:0.22785\n",
      "[746]\tvalidation_0-logloss:0.22785\n",
      "[747]\tvalidation_0-logloss:0.22785\n",
      "[748]\tvalidation_0-logloss:0.22785\n",
      "[749]\tvalidation_0-logloss:0.22784\n",
      "[750]\tvalidation_0-logloss:0.22785\n",
      "[751]\tvalidation_0-logloss:0.22784\n",
      "[752]\tvalidation_0-logloss:0.22784\n",
      "[753]\tvalidation_0-logloss:0.22784\n",
      "[754]\tvalidation_0-logloss:0.22784\n",
      "[755]\tvalidation_0-logloss:0.22783\n",
      "[756]\tvalidation_0-logloss:0.22783\n",
      "[757]\tvalidation_0-logloss:0.22783\n",
      "[758]\tvalidation_0-logloss:0.22783\n",
      "[759]\tvalidation_0-logloss:0.22783\n",
      "[760]\tvalidation_0-logloss:0.22782\n",
      "[761]\tvalidation_0-logloss:0.22783\n",
      "[762]\tvalidation_0-logloss:0.22783\n",
      "[763]\tvalidation_0-logloss:0.22784\n",
      "[764]\tvalidation_0-logloss:0.22784\n",
      "[765]\tvalidation_0-logloss:0.22784\n",
      "[766]\tvalidation_0-logloss:0.22784\n",
      "[767]\tvalidation_0-logloss:0.22784\n",
      "[768]\tvalidation_0-logloss:0.22784\n",
      "[769]\tvalidation_0-logloss:0.22784\n",
      "[770]\tvalidation_0-logloss:0.22784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, eval_set=[(x_val, y_val)], eval_metric='logloss', early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9099254631152033, 0.5674430846163969)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "accuracy_score(y_val, y_pred), f1_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
