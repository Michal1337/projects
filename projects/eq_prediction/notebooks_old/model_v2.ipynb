{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM. 8 featerow - mag, x, y, depth, dist, distance, plate, days_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 08:44:40.426855: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-22 08:44:40.427383: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-22 08:44:40.430657: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-22 08:44:40.834919: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 08:44:44.548727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 08:44:49.991946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 08:44:51.147387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 08:44:51.147491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 08:44:51.163472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 08:44:51.163804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 08:44:51.163993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 08:44:56.372597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 08:44:56.372739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 08:44:56.372754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-22 08:44:56.372944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 08:44:56.373593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3886 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "ds_train = tf.data.Dataset.load(\"../data/ds_final_train_old/\")\n",
    "ds_val = tf.data.Dataset.load(\"../data/ds_final_val_old/\")\n",
    "ds_test = tf.data.Dataset.load(\"../data/ds_final_test_old/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BLOCK_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_element(features, context, labels):\n",
    "    labels = tf.cast(labels, tf.int32)\n",
    "    labels = tf.one_hot(labels, depth=2)\n",
    "    return (features[:,:-2], features[:,-2], features[:,-1]), labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(transform_element)\n",
    "ds_val = ds_val.map(transform_element)\n",
    "ds_test = ds_test.map(transform_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 6)\n",
      "(64,)\n",
      "(64,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "for x, y in ds_train.take(1):\n",
    "    print(x[0].shape)\n",
    "    print(x[1].shape)\n",
    "    print(x[2].shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, n_embed):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embed_dd = tf.keras.layers.Embedding(100, n_embed // 8)\n",
    "        self.embed_plate = tf.keras.layers.Embedding(100, n_embed // 8)\n",
    "        self.lstm_embed = tf.keras.layers.LSTM(n_embed // 8 * 6, return_sequences=True)\n",
    "        self.lstm1 = tf.keras.layers.LSTM(n_embed, return_sequences=True)\n",
    "        self.lstm2 = tf.keras.layers.LSTM(n_embed)\n",
    "        self.dense1 = tf.keras.layers.Dense(n_embed, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(2, activation='softmax')\n",
    "        self.conc = tf.keras.layers.Concatenate(axis=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        cont, plate, dd = inputs\n",
    "        x1 = self.embed_dd(dd)\n",
    "        x2 = self.embed_plate(plate)\n",
    "        x3 = self.lstm_embed(cont)\n",
    "        x = self.conc([x1, x2, x3])\n",
    "        x = self.lstm1(x)\n",
    "        x = self.lstm2(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82498"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=[(None, 64, 6), (None, 64), (None, 64)])\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy', tf.keras.metrics.F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 08:45:09.384896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8904\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /home/majkel/miniconda3/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2023-11-22 08:45:11.379921: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feecc065320 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 08:45:11.380027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060 with Max-Q Design, Compute Capability 7.5\n",
      "2023-11-22 08:45:11.440971: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-22 08:45:11.893644: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3227/3227 [==============================] - 294s 87ms/step - loss: 0.2055 - accuracy: 0.9383 - f1_score: 0.4915 - val_loss: 0.2207 - val_accuracy: 0.9377 - val_f1_score: 0.4839\n",
      "Epoch 2/10\n",
      "3227/3227 [==============================] - 317s 98ms/step - loss: 0.1620 - accuracy: 0.9469 - f1_score: 0.6645 - val_loss: 0.2185 - val_accuracy: 0.9397 - val_f1_score: 0.5643\n",
      "Epoch 3/10\n",
      "3227/3227 [==============================] - 304s 94ms/step - loss: 0.1585 - accuracy: 0.9486 - f1_score: 0.6843 - val_loss: 0.2183 - val_accuracy: 0.9429 - val_f1_score: 0.5872\n",
      "Epoch 4/10\n",
      "3227/3227 [==============================] - 281s 87ms/step - loss: 0.1552 - accuracy: 0.9496 - f1_score: 0.6839 - val_loss: 0.2098 - val_accuracy: 0.9418 - val_f1_score: 0.5700\n",
      "Epoch 5/10\n",
      "3227/3227 [==============================] - 275s 85ms/step - loss: 0.1535 - accuracy: 0.9497 - f1_score: 0.6864 - val_loss: 0.2107 - val_accuracy: 0.9416 - val_f1_score: 0.5654\n",
      "Epoch 6/10\n",
      "3227/3227 [==============================] - 282s 87ms/step - loss: 0.1532 - accuracy: 0.9499 - f1_score: 0.6913 - val_loss: 0.2072 - val_accuracy: 0.9424 - val_f1_score: 0.5766\n",
      "Epoch 7/10\n",
      "3227/3227 [==============================] - 336s 104ms/step - loss: 0.1514 - accuracy: 0.9505 - f1_score: 0.6943 - val_loss: 0.2077 - val_accuracy: 0.9420 - val_f1_score: 0.5713\n",
      "Epoch 8/10\n",
      "3227/3227 [==============================] - 389s 120ms/step - loss: 0.1503 - accuracy: 0.9509 - f1_score: 0.6993 - val_loss: 0.2133 - val_accuracy: 0.9419 - val_f1_score: 0.5673\n",
      "Epoch 9/10\n",
      "3227/3227 [==============================] - 378s 117ms/step - loss: 0.1499 - accuracy: 0.9509 - f1_score: 0.7018 - val_loss: 0.2129 - val_accuracy: 0.9420 - val_f1_score: 0.5680\n",
      "Epoch 10/10\n",
      "3227/3227 [==============================] - 360s 112ms/step - loss: 0.1483 - accuracy: 0.9509 - f1_score: 0.7061 - val_loss: 0.2025 - val_accuracy: 0.9427 - val_f1_score: 0.5846\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, epochs=10, validation_data=ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 11s 105ms/step - loss: 0.0891 - accuracy: 0.9799 - f1_score: 0.6845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08910027891397476,\n",
       " 0.9798869490623474,\n",
       " array([0.9897778 , 0.37929985], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/model_v2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "history = pd.DataFrame.from_dict(history.history)\n",
    "history.to_csv(\"../models/history_model_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
