{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD\n",
    "# LSTM. 8 featerow - mag, x, y, depth, dist, distance, plate, days_diff. TESTING NEW TIMESTEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 07:25:55.272053: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-22 07:25:55.272199: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-22 07:25:55.276386: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-22 07:25:55.562788: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 07:25:57.642412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 07:26:01.250238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 07:26:01.578435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 07:26:01.578508: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 07:26:01.582902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 07:26:01.582988: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 07:26:01.583033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 07:26:04.046490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 07:26:04.046592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 07:26:04.046603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-22 07:26:04.046665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 07:26:04.046688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3886 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "ds_train = tf.data.Dataset.load(\"../data/ds_final_train_new_timesteps/\")\n",
    "ds_val = tf.data.Dataset.load(\"../data/ds_final_val_new_timesteps/\")\n",
    "ds_test = tf.data.Dataset.load(\"../data/ds_final_test_new_timesteps/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BLOCK_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_element(features, context, labels):\n",
    "    labels = tf.cast(labels, tf.int32)\n",
    "    labels = tf.one_hot(labels, depth=2)\n",
    "    return (features[:,:-2], features[:,-2], features[:,-1]), labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(transform_element)\n",
    "ds_val = ds_val.map(transform_element)\n",
    "ds_test = ds_test.map(transform_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 6)\n",
      "(64,)\n",
      "(64,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "for x, y in ds_train.take(1):\n",
    "    print(x[0].shape)\n",
    "    print(x[1].shape)\n",
    "    print(x[2].shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, n_embed):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embed_dd = tf.keras.layers.Embedding(100, n_embed // 8)\n",
    "        self.embed_plate = tf.keras.layers.Embedding(100, n_embed // 8)\n",
    "        self.emebd_cont = tf.keras.layers.LSTM(n_embed // 8 * 6, return_sequences=True)\n",
    "        self.lstm1 = tf.keras.layers.LSTM(n_embed, return_sequences=True)\n",
    "        self.lstm2 = tf.keras.layers.LSTM(n_embed)\n",
    "        self.conc = tf.keras.layers.Concatenate()\n",
    "        self.dense1 = tf.keras.layers.Dense(n_embed, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(2, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        cont, plate, dd = inputs\n",
    "        x1 = self.embed_dd(dd)\n",
    "        x2 = self.embed_plate(plate)\n",
    "        x3 = self.emebd_cont(cont)\n",
    "        x = self.conc([x1, x2, x3])\n",
    "        x = self.lstm1(x)\n",
    "        x = self.lstm2(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82498"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=[(None, 64, 6), (None, 64), (None, 64)])\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy', tf.keras.metrics.F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 07:26:16.387031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8904\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /home/majkel/miniconda3/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2023-11-22 07:26:17.631640: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efd542118c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 07:26:17.631759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060 with Max-Q Design, Compute Capability 7.5\n",
      "2023-11-22 07:26:17.646390: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-22 07:26:17.815592: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3227/3227 [==============================] - 343s 103ms/step - loss: 0.2076 - accuracy: 0.9398 - f1_score: 0.5125 - val_loss: 0.2225 - val_accuracy: 0.9377 - val_f1_score: 0.4839\n",
      "Epoch 2/10\n",
      "3227/3227 [==============================] - 452s 140ms/step - loss: 0.1979 - accuracy: 0.9412 - f1_score: 0.5504 - val_loss: 0.2157 - val_accuracy: 0.9415 - val_f1_score: 0.5644\n",
      "Epoch 3/10\n",
      "3227/3227 [==============================] - 387s 120ms/step - loss: 0.1696 - accuracy: 0.9473 - f1_score: 0.6471 - val_loss: 0.2137 - val_accuracy: 0.9410 - val_f1_score: 0.5570\n",
      "Epoch 4/10\n",
      "3227/3227 [==============================] - 311s 96ms/step - loss: 0.1590 - accuracy: 0.9481 - f1_score: 0.6676 - val_loss: 0.2105 - val_accuracy: 0.9411 - val_f1_score: 0.5500\n",
      "Epoch 5/10\n",
      "3227/3227 [==============================] - 306s 95ms/step - loss: 0.1556 - accuracy: 0.9488 - f1_score: 0.6741 - val_loss: 0.2092 - val_accuracy: 0.9414 - val_f1_score: 0.5603\n",
      "Epoch 6/10\n",
      "3227/3227 [==============================] - 304s 94ms/step - loss: 0.1560 - accuracy: 0.9492 - f1_score: 0.6778 - val_loss: 0.2025 - val_accuracy: 0.9377 - val_f1_score: 0.4839\n",
      "Epoch 7/10\n",
      "3227/3227 [==============================] - 325s 101ms/step - loss: 0.1532 - accuracy: 0.9494 - f1_score: 0.6806 - val_loss: 0.2093 - val_accuracy: 0.9409 - val_f1_score: 0.5400\n",
      "Epoch 8/10\n",
      "3227/3227 [==============================] - 441s 137ms/step - loss: 0.1521 - accuracy: 0.9500 - f1_score: 0.6860 - val_loss: 0.2072 - val_accuracy: 0.9418 - val_f1_score: 0.5632\n",
      "Epoch 9/10\n",
      "3227/3227 [==============================] - 424s 131ms/step - loss: 0.1518 - accuracy: 0.9502 - f1_score: 0.6851 - val_loss: 0.2040 - val_accuracy: 0.9418 - val_f1_score: 0.5647\n",
      "Epoch 10/10\n",
      "3227/3227 [==============================] - 372s 115ms/step - loss: 0.1496 - accuracy: 0.9504 - f1_score: 0.6935 - val_loss: 0.2042 - val_accuracy: 0.9420 - val_f1_score: 0.5710\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, epochs=10, validation_data=ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.0889 - accuracy: 0.9797 - f1_score: 0.6826"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 82ms/step - loss: 0.0872 - accuracy: 0.9803 - f1_score: 0.6834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0872003436088562,\n",
       " 0.9802618026733398,\n",
       " array([0.98997205, 0.37682965], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/model_v2_new_ts.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "history = pd.DataFrame.from_dict(history.history)\n",
    "history.to_csv(\"../models/history_model_v2_new_ts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
